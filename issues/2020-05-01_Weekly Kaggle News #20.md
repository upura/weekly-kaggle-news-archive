# Weekly Kaggle News #20
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-20-243300
<h3><h2>News &amp; Competitions</h2><p>ゴールデンウィークを迎えるに当たって、多くのコンペティションプラットフォームの動きが活発な週でした。</p><p>Kaggleでは27日、画像に埋め込まれたデータを検知する「<a href="https://www.kaggle.com/c/alaska2-image-steganalysis" target="_blank">ALASKA2 Image Steganalysis</a>」コンペが始まりました。30日には<a href="https://www.kaggle.com/c/alaska2-image-steganalysis/discussion/147182" target="_blank">評価指標の変更が発表</a>されています。</p><p>SIGNATEでは27日に「<a href="https://signate.jp/competitions/256" target="_blank">第3回AIエッジコンテスト（アルゴリズムコンテスト②）</a>」が始まりました。タスクは車両前方カメラ画像を活用した物体追跡です。実際のプロ野球データを用いて配球を予測する「<a href="https://signate.jp/competitions/274" target="_blank">プロ野球データを用いた配球予測</a>」も28日に開始されました。「球種予測部門」「コース予測部門」「アイデア部門」の3部門を併設。主催はひろしまサンドボックス推進協議会事務局で、広島にまつわるユニークな賞品が用意されています。</p><p>ProbSpaceは28日に「<a href="https://prob.space/competitions/youtube-view-count" target="_blank">YouTube動画視聴回数予測</a>」コンペを開始しました。YouTubeのサムネイル画像・タイトル・説明文・投稿者などの情報を用いて、視聴回数を予測するマルチモーダルコンペです。ProbSpaceでは27日に「<a href="https://prob.space/competitions/real_estate_2020" target="_blank">不動産取引価格予測</a>」コンペが終了しました。1位のソースコードは「<a href="https://prob.space/competitions/real_estate_2020/discussions/chun1182-Post3748b67697bb27cb59e8" target="_blank">トピック</a>」にて公開されています。</p><p>Nishikaでは1日に「<a href="https://www.nishika.com/competitions/5/summary" target="_blank">日本絵画に描かれた人物の顔分類に機械学習で挑戦！</a>」が始まりました。絵巻物・絵本に残されてきた顔貌画像から、性別（男・女）と身分（貴族・武士・化身・庶民）を予測するタスクです。27日にユーザに配信されたメールによると、一部機能の追加とデザインの更新も実施されています。<a href="https://www.nishika.com/competitions" target="_blank">コンペティション</a>に関して、ディスカッションでのファイル添付機能が追加されました。<a href="https://www.nishika.com/qa" target="_blank">Q&amp;A</a>に関しては、質問者名の非表示化・質問作成回答時のファイル添付機能追加・トップページデザイン変更が実施されました。</p><p>新しいプラットフォームとして「<a href="https://quevico.com/ja/" target="_blank">Quevico</a>」が公開されました。運営会社は、主に学生向けのコンペ開催を手掛けている<a href="https://mewcket.co.jp/" target="_blank">株式会社Mewcket</a>です。現時点で2つのコンペが開催されており、<a href="https://twitter.com/tasuvin/status/1255059673226473472?s=20" target="_blank">企業の実データを用いた企画も進んでいる</a>そうです。</p></h3>
<hr>
<p>
<strong style='display: block;'><a href="https://arxiv.org/abs/2004.11339?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">[2004.11339] Rapidly Bootstrapping a Question Answering Dataset for COVID-19</a></strong>

</p>
<p><p>Kaggle「<a href="https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge" target="_blank">COVID-19 Open Research Dataset Challenge (CORD-19)</a>」を通じて作成されたCOVID-19用の質問応答データセット。ver 0.1では124のペアが含まれています。</p></p>
<p>
<img width="140" height="140" alt="【ボタ山話#10】PyCaret解説と機械学習自動化系ツールとの向き合い方 | 白金鉱業.FM" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/886/885/thumb/logo.jpg?1588032741" />
<strong style='display: block;'><a href="https://shirokane-kougyou.fm/episode/25?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">【ボタ山話#10】PyCaret解説と機械学習自動化系ツールとの向き合い方 | 白金鉱業.FM</a> &mdash; <a href="https://shirokane-kougyou.fm/episode/25">shirokane-kougyou.fm</a></strong>
話題のPyCaretと機械学習自動化系ツールについての話しました！
</p>
<div style='clear: both;'></div>
<p><p>先日 v1.0.0 がリリースされて話題となった「<a href="https://pycaret.org/" target="_blank">PyCaret</a>」について、株式会社ブレインパッドのデータサイエンティストが語っているポッドキャスト。実務や個人で機械学習モデリングの自動化系ツールを利用した経験から、PyCaretの使い所を探っています。</p></p>
<p>
<strong style='display: block;'><a href="https://arxiv.org/abs/2004.11694?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">[2004.11694] Identifying Semantically Duplicate Questions Using Data Science Approach: A Quora Case Study</a></strong>

</p>
<p><p>Quoraを題材とした意味的に重複する質問の特定。tf-idfによるベクトル化＋XGBoostやDeep Learningなど、Kaggleでも馴染みの深いアプローチを試しています。</p></p>
<p>
<strong style='display: block;'><a href="https://note.com/y_katayama/n/n30feff33acd9?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">catboostの推論の仕組みを理解する (1/2)｜Yotaro Katayama｜note</a></strong>
 この記事の目的  catboostというライブラリがあります。GBDT(Gradient  Boosting Decesion Tree )という決定木をアンサンブルする方式の識別モデルを学習するものです。同様のライブラリは他にはXGBoostやLightGBMなどが有名です。     CatBoost - state-of-the-art open-source gradient boosting library with categorical features supportCatBoost - state-of-the-art open-source gradient boo
</p>
<p><p>「CatBoost」の推論の仕組みを解説した記事。ソースコードを追いながら、入力から推論結果が得られる過程を紐解いています。</p></p>
<p>
<img width="140" height="140" alt="Text Classification: All Tips and Tricks from 5 Kaggle Competitions | Neptune Blog" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/896/479/thumb/Text-Classification-tips-and-tricks-2.png?1588188117" />
<strong style='display: block;'><a href="https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Text Classification: All Tips and Tricks from 5 Kaggle Competitions | Neptune Blog</a> &mdash; <a href="https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions">neptune.ai</a></strong>
Check out these great tips and tricks that will improve the performance of your text classification model. All from Kaggle’s top NLP competitions.
</p>
<div style='clear: both;'></div>
<p><p>ここ数年のKaggleで開催された文書分類コンペ5つを題材に、Tipsをまとめた記事。前処理・モデリング・アンサンブルなどの観点別に掲載されています。</p></p>
<p>
<img width="140" height="140" alt="【お知らせ】AIトレンド・トップカンファレンス報告（NeurIPS2019）の無料オンライン公開について – 人工知能学会 (The Japanese Society for Artificial Intelligence)" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/901/219/thumb/jsai_logo_base_outlined_fix-1.png?1588265586" />
<strong style='display: block;'><a href="https://www.ai-gakkai.or.jp/no78_jsai_seminar_online/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">【お知らせ】AIトレンド・トップカンファレンス報告（NeurIPS2019）の無料オンライン公開について – 人工知能学会 (The Japanese Society for Artificial Intelligence)</a> &mdash; <a href="https://www.ai-gakkai.or.jp/no78_jsai_seminar_online/">www.ai-gakkai.or.jp</a></strong>

</p>
<div style='clear: both;'></div>
<p><p>人工知能学会が「NeurIPS 2019」の報告資料3件を音声付きスライド映像と共に公開。「<a href="https://www.slideshare.net/secret/eOf13JfmWCDILM" target="_blank">NeurIPS2019における自然言語処理</a>」は近年の自然言語処理にまつわる研究動向が端的にまとまっています。</p></p>
<p>
<img width="140" height="140" alt="NGBoostを読んで実装する - nykergoto’s blog" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/901/365/thumb/20200501014022.png?1588268111" />
<strong style='display: block;'><a href="https://nykergoto.hatenablog.jp/entry/2020/05/01/NGBoost%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E5%AE%9F%E8%A3%85%E3%81%99%E3%82%8B?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">NGBoostを読んで実装する - nykergoto’s blog</a> &mdash; <a href="https://nykergoto.hatenablog.jp/entry/2020/05/01/NGBoost%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E5%AE%9F%E8%A3%85%E3%81%99%E3%82%8B">nykergoto.hatenablog.jp</a></strong>
不確実性を考慮した予測が可能と噂の NGBoost の論文を読んでみたので、全体のながれをまとめて見ました。加えて自分でも NGBoost を実装して、その結果を載せています。 元の論文 NGBoost: Natural Gradient Boosting for Probabilistic Prediction はこちら https://arxiv.org/abs/1910.03225。 Introduction 一般的な教師あり学習を考えます。このとき予測モデルは入力データ $X$ に対して予測値 $y$ を出力するように学習していきますが、たいていのモデルではひとつのデータに対しては予測…
</p>
<div style='clear: both;'></div>
<p><p>数式も交えた「NGBoost」の解説記事。最適化の流れを噛み砕いて説明しているだけではなく、独自の実装も公開しています。</p></p>
