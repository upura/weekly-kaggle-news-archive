# Weekly Kaggle News #31
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-31-262758
<h3><h2>News</h2><p>Kaggleの共同創業者でCTOの<a href="https://www.kaggle.com/benhamner" target="_blank">Ben Hamner</a>さんは11日、全米を中心に「Black Lives Matter」を合言葉として広がる活動に対する<a href="https://www.kaggle.com/general/165766" target="_blank">Kaggleの取り組み</a>を示しました。今後1年間にコンペやイベントなどを通じて、人種の平等に寄与する活動を展開すると表明。趣旨に沿った取り組みを奨励し、活動促進のためのスポンサー費用10万ドルを提供すると明らかにしました。</p><p><a href="https://www.kaggle.com/cdeotte" target="_blank">Chris Deotte</a>さんが、Kaggleの全4カテゴリでGrandmasterの称号を獲得しました。<a href="https://www.kaggle.com/abhishek?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">Abhishek</a>さんに続く史上2人目の快挙で、Kaggle公式アカウントも<a href="https://twitter.com/kaggle/status/1283124119043792899" target="_blank">祝福</a>しています。ChrisさんのKaggle登録日は2018年3月で、約2年という短期間での達成も驚きです。</p><h2>Competitions</h2><p>Kaggleで開催中の「<a href="https://www.kaggle.com/c/global-wheat-detection?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">Global Wheat Detection</a>」コンペについて、ライブラリのライセンスに関する要件が<a href="https://www.kaggle.com/c/global-wheat-detection/discussion/165735" target="_blank">明示</a>されました。コンペの最終的な提出としてはMITライセンスを要求しています。高スコアの公開Notebook内で利用されていた「YoloV5」などのライブラリがこの規定に抵触します。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="Colab on steroids: free GPU instances with SSH access and Visual Studio Code Server | Towards Data Science" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/258/163/thumb/1*SdaD1l98mXDepmjMm3U9Fg.png?1594915859" />
<strong style='display: block;'><a href="https://towardsdatascience.com/colab-free-gpu-ssh-visual-studio-code-server-36fe1d3c5243?gi=4b83d03be00b&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Colab on steroids: free GPU instances with SSH access and Visual Studio Code Server | Towards Data Science</a> &mdash; <a href="https://towardsdatascience.com/colab-free-gpu-ssh-visual-studio-code-server-36fe1d3c5243?gi=4b83d03be00b">towardsdatascience.com</a></strong>
How to have SSH access (with ngrok) and install Visual Studio Code Server on Google Colaboratory free GPU instances.
</p>
<div style='clear: both;'></div>
<p><p>ブラウザ上のPython実行環境「Google Colab」から「Visual Studio Code Server」にアクセスする方法を紹介している記事。この記事を受けての<a href="https://memo.chezo.uno/Google-Colaboratory-VS-Code-code-server-3b0f4ae8181c49ecac0c99f6e4017133" target="_blank">日本語の解説記事</a>も出ています。</p></p>
<p>
<img width="140" height="140" alt="強化学習/RL/Reinforcement Learning のデバッグ方法 - higepon blog" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/243/838/thumb/1594636580?1594653764" />
<strong style='display: block;'><a href="https://higepon.hatenablog.com/entry/2020/07/13/193620?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">強化学習/RL/Reinforcement Learning のデバッグ方法 - higepon blog</a> &mdash; <a href="https://higepon.hatenablog.com/entry/2020/07/13/193620">higepon.hatenablog.com</a></strong>
RL のデバッグは難しい。RLアルゴリズムの選択、適切な reward の設定、Deep RLの場合モデルの選定、実装の正しさ、適切なパラメータ、そもそも学習できる問題なのか。切り分けが難しい。世の中には同じように思っている人がたくさんいるようだ。情報元から適当にまとめる。 情報元 What are your best tips for debugging RL problems? : reinforcementlearning Deep Reinforcement Learning practical tips : reinforcementlearning williamFalcon/De…
</p>
<div style='clear: both;'></div>
<p><p>強化学習のデバッグ方法におけるチェックリストをまとめている記事。Kaggleでも「<a href="https://www.kaggle.com/c/halite" target="_blank">Halite by Two Sigma</a>」コンペなど強化学習が題材のコンペが増えつつあります。</p></p>
<p>
<strong style='display: block;'><a href="https://www.kaggle.com/jobs/20017/hiring-kaggle-grandmasters-and-masters-in-china?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Machine Learning and Data Science Job Openings | Kaggle</a></strong>
The jobs board sources career openings for data professionals like you. Subscribe to be notified of new opportunities in data science, machine learning, statistics, and other data analytics jobs.
</p>
<p><p>「Hiring Kaggle Grandmasters and Masters in China!」と題したH2O.ai社の募集要項。業務内容にコンペ参加が含まれています。</p></p>
<p>
<img width="140" height="140" alt="kaggle tweet コンペの話" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/243/868/thumb/kaggletweetcompetition-200712235246-thumbnail-4.jpg?1594654148" />
<strong style='display: block;'><a href="https://www.slideshare.net/taguchinaoya/kaggle-tweet?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">kaggle tweet コンペの話</a> &mdash; <a href="https://www.slideshare.net/taguchinaoya/kaggle-tweet">www.slideshare.net</a></strong>
kaggle tweet コンペでの経験と得た知見の共有 :) -- Share our story and the techniques we've achieved in the kaggle tweet sentiment extraction competition.
</p>
<div style='clear: both;'></div>
<p><p>6月に終了したKaggle「<a href="https://www.kaggle.com/c/tweet-sentiment-extraction?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">Tweet Sentiment Extraction</a>」コンペで5位に入った方の参加録。時系列に沿って具体的な取り組みが掲載されており、上位解法も紹介されています。</p></p>
<p>
<img width="140" height="140" alt="CVPR2020 Report - Speaker Deck" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/258/172/thumb/slide_0.jpg?1594915941" />
<strong style='display: block;'><a href="https://speakerdeck.com/motokimura/cvpr2020-report?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">CVPR2020 Report - Speaker Deck</a> &mdash; <a href="https://speakerdeck.com/motokimura/cvpr2020-report">speakerdeck.com</a></strong>

</p>
<div style='clear: both;'></div>
<p><p>コンピュータビジョン分野の世界最大の国際会議「<a href="http://cvpr2020.thecvf.com/" target="_blank">CVPR2020</a>」のまとめ資料。オンライン開催の模様や採択論文の傾向を紹介しつつ、42本の論文やワークショップについて解説しています。</p></p>
<p>
<img width="140" height="140" alt="flairを使って最速でNLPのベースラインモデルを作る - moriyamaのエンジニアリング備忘録" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/233/569/thumb/20200710133947.png?1594386957" />
<strong style='display: block;'><a href="https://nmoriyama.hatenablog.com/entry/2020/07/10/160031?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">flairを使って最速でNLPのベースラインモデルを作る - moriyamaのエンジニアリング備忘録</a> &mdash; <a href="https://nmoriyama.hatenablog.com/entry/2020/07/10/160031">nmoriyama.hatenablog.com</a></strong>
自然言語処理に限らず、機械学習関連のプロジェクトではスタート時は、なるべく複雑なコーディングをせずにシンプルなベースラインモデルを低コストで作成し、そこからデータの傾向やタスクの複雑さを把握することが重要です。 ところが自然言語処理では前処理のコストが高く、最低限でも単語分割、ベクトル化、深層学習を用いる場合は事前学習された埋め込みベクトルを準備する必要があります。その後は他のタスクと同様にモデルの保存方法や、予測のパイプラインで悩みポイントを抱えることが多いと思います。 最近はAutoMLを始めとした機械学習の自動化が進歩し、初手から高性能なモデルをブラウザ上で数クリックで作成できますが、中…
</p>
<div style='clear: both;'></div>
<p><p>自然言語処理ライブラリ「<a href="https://github.com/flairNLP/flair" target="_blank">flair</a>」の紹介記事。「<a href="https://www.rondhuit.com/download.html" target="_blank">livedoor ニュースコーパス</a>」を用いた日本語文書の分類タスクを解いています。</p></p>
<p>
<img width="140" height="140" alt="形態素解析器比較 Sudachi vs Mecab+Neologd - tdualのブログ" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/246/463/thumb/20200713160434.png?1594714663" />
<strong style='display: block;'><a href="http://tdual.hatenablog.com/entry/2020/07/13/162151?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">形態素解析器比較 Sudachi vs Mecab+Neologd - tdualのブログ</a> &mdash; <a href="http://tdual.hatenablog.com/entry/2020/07/13/162151">tdual.hatenablog.com</a></strong>
ブレインパッドさんのpodcast「白金鉱業.FM」の聞いてたらSudachiの開発の話を聞いて興味が出たので触ってみました。 shirokane-kougyou.fm （「白金鉱業.FM」はデータ分析現場の生の声が聴けるのでなかなか面白いです。） Sudachiとは 使ってみる 比較 データセット 使用したモジュール トークナイザー トークナイザー使用例 辞書の統計的フィルター ベクトル化 分類器 結果 Sudachi(モードA) Sudachi(モードB) Sudachi(モードC) Mecab+Neologd 速度について その他 品詞の付与について 終わりに Sudachiとは ワーク…
</p>
<div style='clear: both;'></div>
<p><p>「<a href="https://www.rondhuit.com/download.html" target="_blank">livedoor ニュースコーパス</a>」を用いた日本語文書の分類タスクを通じて、形態素解析器の「Sudachi」と「MeCab」での結果を比較している記事。Sudachiの開発者がゲスト参加した<a href="https://shirokane-kougyou.fm/episode/35" target="_blank">Podcast</a>を受けてまとめられた記事です。</p></p>
<p>
<strong style='display: block;'><a href="https://qiita.com/namahoge/items/71be06c8fe37e88909c9?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Pytorch+Tensorflowのちゃんぽんコードのすゝめ（tfdsでpytorchをブーストさせる話） - Qiita</a></strong>

</p>
<p><p>実験速度の改善を目指して、TensorFlowでデータ読み込み部分を書き、PyTorchでモデル構築する方法を検証している記事。実装コードとともに、速度検証の結果を掲載しています。</p></p>
<p>
<img width="140" height="140" alt="How Disney uses PyTorch for animated character recognition | by PyTorch | PyTorch | Jul, 2020 | Medium" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/258/201/thumb/0*MD9iFWdKZ90xIbaz?1594916328" />
<strong style='display: block;'><a href="https://medium.com/pytorch/how-disney-uses-pytorch-for-animated-character-recognition-a1722a182627?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">How Disney uses PyTorch for animated character recognition | by PyTorch | PyTorch | Jul, 2020 | Medium</a> &mdash; <a href="https://medium.com/pytorch/how-disney-uses-pytorch-for-animated-character-recognition-a1722a182627">medium.com</a></strong>
The long and incremental evolution of the media industry, from a traditional broadcast and home video model, to a more mixed model with increasingly digitally-accessible content, has accelerated the…
</p>
<div style='clear: both;'></div>
<p><p>ディズニーがアニメキャラクターの顔認識にPyTorchを使っている話。データセットの拡張や高速化のためのバッチ処理の工夫など、性能向上に向けた試行錯誤も記載されています。</p></p>
