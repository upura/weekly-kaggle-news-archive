# Weekly Kaggle News #42
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-42-280794
<h3><h2>News</h2><p>Pythonの新バージョン3.9のリリースが10月5日に迫っています。新機能を紹介している<a href="https://www.python.jp/pages/python3.9.html" target="_blank">記事</a>が9月28日に公開されました。</p><p>Kaggle上の通知機能の追加が<a href="https://www.kaggle.com/product-feedback/187713" target="_blank">告知</a>されました。実行したNotebookの実行完了や、参加コンペのリマインダを通知する機能が数週間のうちに実装されるようです。1日ごろには、Kaggleの順位表でのユーザアイコンの表示デザインに変更がありました。</p><p>日本のKaggleコミュニティ「<a href="https://yutori-datascience.hatenablog.com/entry/2017/08/23/143146" target="_blank">kaggler-ja</a>」のSlackワークスペースの参加人数が<a href="https://twitter.com/tkm2261/status/1310080846871764993?s=20" target="_blank">10000人を突破</a>しました。2017年8月の開設から約3年を経ての達成です。初心者用の質問チャンネルが特に活発な印象で、過去ログも<a href="https://kaggler-ja-slack-archive.appspot.com/" target="_blank">公開</a>されています。</p><p>機械学習ライブラリ「PyTorch」について30日、Google開発の機械学習特化プロセッサ「TPU」の<a href="https://medium.com/pytorch/pytorch-xla-is-now-generally-available-on-google-cloud-tpus-f9267f437832" target="_blank">正式提供の開始</a>が発表されました。Google ColabやKaggle Notebookでも利用可能となっています。29には、PyTorchの機能を有したR言語のパッケージが管理サイト「CRAN」に<a href="https://blogs.rstudio.com/ai/posts/2020-09-29-introducing-torch-for-r/" target="_blank">追加</a>されました。</p><h2>Competitions</h2><p>Kaggle「<a href="https://www.kaggle.com/c/landmark-recognition-2020" target="_blank">Google Landmark Recognition 2020</a>」コンペが29日に終了しました。毎年恒例の画像認識コンペで、<a href="https://www.kaggle.com/c/landmark-recognition-2020/discussion/187821" target="_blank">優勝解法</a>も公開されています。</p><p>Kaggle「<a href="https://www.kaggle.com/c/google-football" target="_blank">Google Research Football with Manchester City F.C.</a>」コンペが28日に始まりました。Googleと英サッカークラブ「マンチェスターC」によるメダルありの強化学習コンペです。</p><h2>Errata</h2><p><a href="https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-41-279125" target="_blank">Weekly Kaggle News #41</a>のKaggle「<a href="https://www.kaggle.com/c/halite" target="_blank">Halite by Two Sigma</a>」コンペに関する記事で「深層強化学習を用いた解法でした」とありましたが「解法によると深層強化学習にも取り組んでいたようです」に修正しました。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="Anyscale - Announcing Ray 1.0" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/591/904/thumb/ray1.png?1601566448" />
<strong style='display: block;'><a href="https://www.anyscale.com/blog/announcing-ray-1-0?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Anyscale - Announcing Ray 1.0</a> &mdash; <a href="https://www.anyscale.com/blog/announcing-ray-1-0">www.anyscale.com</a></strong>
From the creators of Ray, Anyscale is a framework for building machine learning applications at any scale originating from the UC Berkeley RISELab.
</p>
<div style='clear: both;'></div>
<p><p>分散並列処理フレームワーク「Ray」の<a href="https://github.com/ray-project/ray/releases/tag/ray-1.0.0" target="_blank">v1.0.0</a>が30日に公開されました。ハイパーパラメータ調整の<a href="https://docs.ray.io/en/latest/tune/" target="_blank">Ray Tune</a>など、高機能なライブラリも提供しています。</p></p>
<p>
<img width="140" height="140" alt="CuPy v8.0.0 をリリースしました | Preferred Networks Research &amp; Development" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/594/831/thumb/image4.png?1601624613" />
<strong style='display: block;'><a href="https://tech.preferred.jp/ja/blog/cupy-v8/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">CuPy v8.0.0 をリリースしました | Preferred Networks Research &amp; Development</a> &mdash; <a href="https://tech.preferred.jp/ja/blog/cupy-v8/">tech.preferred.jp</a></strong>
<p>本日、CuPy v8.0.0をリリースしました。主要な新機能や性能向上は以下の通りです。 </p>
</p>
<div style='clear: both;'></div>
<p><p>GPU計算を手軽に実装するためのライブラリ「CuPy」の<a href="https://github.com/cupy/cupy/releases/tag/v8.0.0" target="_blank">v8.0.0</a>が1日に公開されました。行列演算の高速化や、ハイパーパラメータ調整ライブラリ「Optuna」を用いた最適化などが盛り込まれています。</p></p>
<p>
<img width="140" height="140" alt="deeplearning/RecSys2020Tutorial at main · rapidsai/deeplearning · GitHub" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/562/577/thumb/43887749?1601101359" />
<strong style='display: block;'><a href="https://github.com/rapidsai/deeplearning/tree/main/RecSys2020Tutorial?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">deeplearning/RecSys2020Tutorial at main · rapidsai/deeplearning · GitHub</a> &mdash; <a href="https://github.com/rapidsai/deeplearning/tree/main/RecSys2020Tutorial">github.com</a></strong>
Contribute to rapidsai/deeplearning development by creating an account on GitHub.
</p>
<div style='clear: both;'></div>
<p><p>推薦システムに関する国際会議「RecSys」での<a href="https://recsys.acm.org/recsys20/tutorials/" target="_blank">特徴量エンジニアリングのチュートリアル</a>資料。Kaggle Grandmasterの<a href="https://www.kaggle.com/cdeotte" target="_blank">Chris Deotte</a>さんらによる充実した内容で、GPUを用いた高速化についても言及されています。</p></p>
<p>
<img width="140" height="140" alt="Watch Live Conference Sessions | GTC Oct 2020 | NVIDIA" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/591/881/thumb/GTC20-Fall-OG-TWITTER-IAMAI-globe-1200x630.jpg?1601566168" />
<strong style='display: block;'><a href="https://www.nvidia.com/en-us/gtc/session-catalog/?ncid=so-twit-74735&amp;search=A21139&amp;search.language=1594320459782001LCjF&amp;tab.catalogtabfields=1600209910618001TWM3&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Watch Live Conference Sessions | GTC Oct 2020 | NVIDIA</a> &mdash; <a href="https://www.nvidia.com/en-us/gtc/session-catalog/?ncid=so-twit-74735&amp;search=A21139&amp;search.language=1594320459782001LCjF&amp;tab.catalogtabfields=1600209910618001TWM3">www.nvidia.com</a></strong>
Register to watch live conference sessions in your timezone or select from a wide variety of on-demand content.
</p>
<div style='clear: both;'></div>
<p><p>「<a href="https://recsys-twitter.com/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">RecSys Challenge 2020</a>」の優勝解法についての講演が7、8日に実施されます。GPUを活用して大規模データを前処理・学習した取り組みです。</p></p>
<p>
<strong style='display: block;'><a href="https://qiita.com/kunishou/items/bd5fad9a334f4f5be51c?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Python初学者のためのPandas100本ノック - Qiita</a></strong>
<p>PythonライブラリであるPandasを効率的に学ぶためのコンテンツとして「Python初学者のためのPandas100本ノック」を作成したので公開します。</p>
</p>
<p><p>テーブル形式データを処理する「Pandas」を効率的に学ぶための問題集。データ集計・抽出・可視化などの基本操作を取り扱っています。</p></p>
<p>
<img width="140" height="140" alt="鳥コンペ反省会 (2020/09/26 13:00〜)" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/594/828/thumb/5b8873efb5db064009a57fbcc453359e.png?1601624562" />
<strong style='display: block;'><a href="https://connpass.com/event/189722/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">鳥コンペ反省会 (2020/09/26 13:00〜)</a> &mdash; <a href="https://connpass.com/event/189722/">connpass.com</a></strong>
<p>先日終わった Cornell Birdcall Identification コンペの反省をする場です。</p>
</p>
<div style='clear: both;'></div>
<p><p>Kaggle「<a href="https://www.kaggle.com/c/birdsong-recognition" target="_blank">Cornell Birdcall Identification</a>」コンペの参加者有志が開催した反省会。<a href="https://togetter.com/li/1598304" target="_blank">Twitterのハッシュタグまとめ</a>や、<a href="https://oregin-ai.hatenablog.com/entry/2020/09/29/204857" target="_blank">公開された資料のまとめ記事</a>も公開されています。</p></p>
<p>
<img width="140" height="140" alt="Kaggle日記という戦い方 | Zenn" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/591/949/thumb/ogp-base_mrsu7s.png?1601566675" />
<strong style='display: block;'><a href="https://zenn.dev/fkubota/articles/3d8afb0e919b555ef068?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Kaggle日記という戦い方 | Zenn</a> &mdash; <a href="https://zenn.dev/fkubota/articles/3d8afb0e919b555ef068">zenn.dev</a></strong>
<p>先日(2020/09/26)行なわれた鳥コンペ反省会でkaggle日記というものを紹介させていただきました。</p>
</p>
<div style='clear: both;'></div>
<p><p>数カ月にわたるKaggleコンペを戦い抜く上でのメモ術を紹介している記事。小規模データでコードを検証しておく実験のコツについても<a href="https://zenn.dev/fkubota/articles/2b8d46b11c178ac2fa2d" target="_blank">記事</a>が公開されています。</p></p>
<p>
<img width="140" height="140" alt="Uber Creates Deep Neural Networks to Generate Training Data for Other Deep Neural Networks | by Jesus Rodriguez | DataSeries | Medium" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/562/821/thumb/1*WEiHObB0jXmTQAqIyjUy2A.png?1601113584" />
<strong style='display: block;'><a href="https://medium.com/dataseries/uber-creates-deep-neural-networks-to-generate-training-data-for-other-deep-neural-networks-553fedcaa74d?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Uber Creates Deep Neural Networks to Generate Training Data for Other Deep Neural Networks | by Jesus Rodriguez | DataSeries | Medium</a> &mdash; <a href="https://medium.com/dataseries/uber-creates-deep-neural-networks-to-generate-training-data-for-other-deep-neural-networks-553fedcaa74d">medium.com</a></strong>
<p>A common analogy in artificial intelligence(AI) circles is that training data is the new oil for machine learning models.</p>
</p>
<div style='clear: both;'></div>
<p><p>Uberが公開した論文「<a href="https://arxiv.org/abs/1912.07768" target="_blank">Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data</a>」の紹介記事。ニューラルネットワークを用いて学習用データセットを生成する取り組みです。</p></p>
<p>
<img width="140" height="140" alt="SIGNATE Student Cup 2020" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/591/771/thumb/hqdefault.jpg?1601564720" />
<strong style='display: block;'><a href="https://www.youtube.com/playlist?list=PLx--cSjgRP_SAF4tCsKvq40kXUMNs2OM4&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">SIGNATE Student Cup 2020</a> &mdash; <a href="https://www.youtube.com/playlist?list=PLx--cSjgRP_SAF4tCsKvq40kXUMNs2OM4">www.youtube.com</a></strong>
Enjoy the videos and music you love, upload original content, and share it all with friends, family, and the world on YouTube.
</p>
<div style='clear: both;'></div>
<p><p>「<a href="https://signate.jp/student-cup" target="_blank">SIGNATE Student Cup 2020</a>」の上位入賞者プレゼンテーションの動画が28日に公開されました。SIGNATEの<a href="https://www.youtube.com/channel/UCHYTFPjNnb5hziQJttbM0sA" target="_blank">公式YouTubeチャンネル</a>には、その他「<a href="https://signate.jp/ai-edge-contest/ja" target="_blank">AIエッジコンテスト</a>」関連の動画などがアップロードされています。</p></p>
<p>
<img width="140" height="140" alt="ひろしまQuest2020#stayhome【アイデア部門】 | SIGNATE - Data Science Competition" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/594/852/thumb/lp7VuhZUbp0JAnnRSVCvXEkGJep3NwJdhD3iITzI.jpeg?1601624941" />
<strong style='display: block;'><a href="https://signate.jp/competitions/277/summary?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">ひろしまQuest2020#stayhome【アイデア部門】 | SIGNATE - Data Science Competition</a> &mdash; <a href="https://signate.jp/competitions/277/summary">signate.jp</a></strong>

</p>
<div style='clear: both;'></div>
<p><p>SIGNATE「<a href="https://signate.jp/competitions/277" target="_blank">ひろしまQuest2020#stayhome【アイデア部門】</a>」コンペの入賞者レポートが公開されました。成果発表会は10月下旬〜11月上旬に<a href="https://signate.jp/competitions/277#schedule" target="_blank">予定</a>されているそうです。</p></p>
<p>
<img width="140" height="140" alt="KagglerへのNumeraiのススメ | Zenn" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/565/845/thumb/ogp-base_mrsu7s.png?1601192722" />
<strong style='display: block;'><a href="https://zenn.dev/katsu1110/articles/bb2b5cba9b04c9e30bfe?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">KagglerへのNumeraiのススメ | Zenn</a> &mdash; <a href="https://zenn.dev/katsu1110/articles/bb2b5cba9b04c9e30bfe">zenn.dev</a></strong>
<p>Numeraiとは、株価を予測するデータサイエンスコンペです。</p>
</p>
<div style='clear: both;'></div>
<p><p>株価予測のプラットフォーム「Numerai」の紹介記事。既にKaggle参加経験のある読者に向けて、Kaggleとの違いを中心に解説しています。</p></p>
<p>
<strong style='display: block;'><a href="https://sites.google.com/view/snlp-jp/home/2020?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">最先端NLP勉強会 - 2020</a></strong>
自然言語処理分野のトップジャーナル・トップ会議であるTACL、ACL、EMNLP、NAACLと直近開催の関連会議（ICLR、ICML、CVPRなど）の論文の中から、参加者の投票によって選ばれた論文を各参加者が分担して紹介する論文読み会です。
</p>
<p><p>25、26日に開催された「最先端NLP勉強会」の発表資料。自然言語処理分野の著名な国際会議に採択された論文について、30件以上の紹介資料が公開されています。</p></p>
<p>
<img width="140" height="140" alt="ECCV2020 papers - Speaker Deck" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/594/924/thumb/slide_0.jpg?1601626364" />
<strong style='display: block;'><a href="https://speakerdeck.com/mot_ai_tech/eccv2020-papers?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">ECCV2020 papers - Speaker Deck</a> &mdash; <a href="https://speakerdeck.com/mot_ai_tech/eccv2020-papers">speakerdeck.com</a></strong>
<p>2020年8月23日から28日にかけてオンラインで開催された、コンピュータビジョン分野で世界最大規模の国際会議であるECCV2020に、DeNAとMoTの研究開発エンジニア5名（加藤直樹、北村博俊、佐々木辰也、中村遵介、林俊宏）が参加しました。</p>
</p>
<div style='clear: both;'></div>
<p><p>コンピュータビジョン分野で著名な国際会議「ECCV2020」のサーベイ資料。参加した研究開発エンジニア5人が選定した論文24本が解説されています。</p></p>
