# Weekly Kaggle News #89
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-89-729332
<h3><h2>News</h2><p>衛星データを用いたコンペを開催する「<a href="https://solafune.com/#/" target="_blank">Solafune</a>」は25日、日本マイクロソフトとの協業を<a href="https://prtimes.jp/main/html/rd/p/000000008.000065306.html" target="_blank">発表</a>しました。衛星データのビジネス利用を推進していくとのことです。これまで「<a href="https://solafune.com/#/competitions/ea90cba4-3e01-42df-9516-9ac0d7a44204" target="_blank">衛星画像から空港利用者数を予測</a>」「<a href="https://solafune.com/#/competitions/f03f39cc-597b-4819-b1a5-41479d4b73d6" target="_blank">夜間光データから土地価格を予測</a>」の2コンペが開催されています。</p><h2>Competitions</h2><p>株式市場での売買戦略を策定するKaggle「<a href="https://www.kaggle.com/c/jane-street-market-prediction?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">Jane Street Market Prediction</a>」コンペが23日に終わりました。2021年2月にコード提出が締め切られ、実データでの最終評価が実施されました。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="rinna社、日本語GPT-2/BERTの事前学習モデルを開発しオープンソース化｜rinna株式会社のプレスリリース" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/010/691/846/thumb/d70041-17-4b04a37793f51afb0b59-3.png?1629947434" />
<strong style='display: block;'><a href="https://prtimes.jp/main/html/rd/p/000000017.000070041.html?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">rinna社、日本語GPT-2/BERTの事前学習モデルを開発しオープンソース化｜rinna株式会社のプレスリリース</a> &mdash; <a href="https://prtimes.jp/main/html/rd/p/000000017.000070041.html">prtimes.jp</a></strong>
rinna株式会社のプレスリリース（2021年8月25日 13時00分）rinna社、日本語GPT-2/BERTの事前学習モデルを開発しオープンソース化
</p>
<div style='clear: both;'></div>
<p><p>rinna株式会社から、日本語に特化したGPT-2とBERTの事前学習済みモデルが公開されました。Megagon Labsから、日本語T5モデルも<a href="https://twitter.com/shirayu/status/1430361402628182016?s=20" target="_blank">公開</a>されています。</p></p>
<p>
<img width="140" height="140" alt="Google Colab Pro+: Is it worth $49.99? | by Benedikt Droste | Aug, 2021 | Towards Data Science" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/010/601/717/thumb/1*uDVIKhMm9E580K0dMP6ayg.png?1629526505" />
<strong style='display: block;'><a href="https://towardsdatascience.com/google-colab-pro-is-it-worth-49-99-c542770b8e56?gi=80ba529a1811&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Google Colab Pro+: Is it worth $49.99? | by Benedikt Droste | Aug, 2021 | Towards Data Science</a> &mdash; <a href="https://towardsdatascience.com/google-colab-pro-is-it-worth-49-99-c542770b8e56?gi=80ba529a1811">towardsdatascience.com</a></strong>
<p>Google Colab is becoming more and more popular for doing deep learning from home, preparing and sharing data science cases and working collaboratively with each other.</p>
</p>
<div style='clear: both;'></div>
<p><p>ブラウザ上のPython実行環境「Google Colaboratory」の課金版の最上位プラン「Pro+」の利点などをまとめた記事。GPUや実行時間なども一覧にしています。</p></p>
<p>
<img width="140" height="140" alt="【インタビュー】当社社員の山本が「Kaggle Grandmaster」称号を取得しました！ | Acroquest Technology株式会社" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/010/652/081/thumb/02600461-9ce8-43d9-8dcc-508a4182ce26?1629782431" />
<strong style='display: block;'><a href="https://www.wantedly.com/companies/acroquest/post_articles/342271?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">【インタビュー】当社社員の山本が「Kaggle Grandmaster」称号を取得しました！ | Acroquest Technology株式会社</a> &mdash; <a href="https://www.wantedly.com/companies/acroquest/post_articles/342271">www.wantedly.com</a></strong>
<p>山本が「Kaggle Grandmaster」称号を取得しました！</p>
</p>
<div style='clear: both;'></div>
<p><p>Grandmasterの称号を獲得した<a href="https://www.kaggle.com/tereka?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">terekaさん</a>のインタビュー記事。7年間の積み重ねや、今後の意気込みが語られています。</p></p>
<p>
<img width="140" height="140" alt="ACL2021のBest PaperのVOLTを日本語文書分類で試してみた結果...！ - Retrieva TECH BLOG" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/010/671/743/thumb/159479255596133?1629892458" />
<strong style='display: block;'><a href="https://tech.retrieva.jp/entry/2021/08/25/185920?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">ACL2021のBest PaperのVOLTを日本語文書分類で試してみた結果...！ - Retrieva TECH BLOG</a> &mdash; <a href="https://tech.retrieva.jp/entry/2021/08/25/185920">tech.retrieva.jp</a></strong>
今回の記事では、先日開催された自然言語処理のトップカンファレンスである、ACL-IJCNLP2021でBest Paperとなった、VOLTを日本語文書分類で試してみた話をします。
</p>
<div style='clear: both;'></div>
<p><p>自然言語処理の国際学会「ACL 2021」でベストペーパーに選ばれた論文について、日本語文書で検証している記事。適切な語彙サイズを自動で決める枠組みを提案しています。</p></p>
<p>
<img width="140" height="140" alt="BERTの推論速度を最大10倍にしてデプロイした話とそのTips - JX通信社エンジニアブログ" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/010/695/480/thumb/082f697a-637e-d12e-8c24-ded0c089c26f.png?1629966719" />
<strong style='display: block;'><a href="https://tech.jxpress.net/entry/2021/08/26/170000?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">BERTの推論速度を最大10倍にしてデプロイした話とそのTips - JX通信社エンジニアブログ</a> &mdash; <a href="https://tech.jxpress.net/entry/2021/08/26/170000">tech.jxpress.net</a></strong>
<p>本記事は以上のような背景から大きなNLPモデルの代表格であるBERTを利用して各高速化手法を検証します。</p>
</p>
<div style='clear: both;'></div>
<p><p>BERTの推論速度を高速化するさまざまな手法を検証している記事。量子化・蒸留・剪定などを、詳細な実験結果と共に紹介しています。</p></p>
