# Weekly Kaggle News #10
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-10-227156
<h3><h2>News</h2><p><a href="https://www.kaggle.com/" target="_blank">Kaggle</a>のUI/UXが大規模に刷新されました。<a href="https://twitter.com/benhamner/status/1228046264559734784?s=20" target="_blank">14日から少数のユーザに順次適用</a>され、現在はほぼ全てのユーザに反映されている模様です。仔細な部分の変更もあり、これまでのUI/UXに慣れている方は、若干戸惑う場面もありそうです。</p><p>日本語の自然言語処理を題材にした書籍『<a href="https://book.mynavi.jp/ec/products/detail/id=113274" target="_blank">機械学習・深層学習による自然言語処理入門 scikit-learnとTensorFlowを使った実践プログラミング</a>』が2月27日に出版されます。目次を見る限り、自然言語処理や機械学習の基礎的な内容から始め、近年の動向であるBERTやAutoMLについても扱っているようです。著者の<a href="https://hironsan.hatenablog.com/" target="_blank">ブログ</a>や<a href="https://qiita.com/Hironsan" target="_blank">Qiita</a>も良質な情報が多く、良著の期待が高まります。</p><h2>Competitions</h2><p>毎年恒例の全米大学体育協会（NCAA）バスケットボールトーナメントに関するコンペが、Kaggleで始まりました。メダルが授与される<a href="https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament" target="_blank">男子</a>・<a href="https://www.kaggle.com/c/google-cloud-ncaa-march-madness-2020-division-1-womens-tournament" target="_blank">女子</a>別の予測性能を争うコンペに加え、メダルなしですが探索的なデータ分析に取り組む<a href="https://www.kaggle.com/c/march-madness-analytics-2020" target="_blank">コンペ</a>も開催されています。</p><p>14日に始まったKaggle「<a href="https://www.kaggle.com/c/abstraction-and-reasoning-challenge" target="_blank">Abstraction and Reasoning Challenge</a>」コンペは、<a href="https://twitter.com/LeapingLlamas/status/1229566374521057281?s=20" target="_blank">サンプル提出のスコアを超える参加者が出ない状況が数日間続きました</a>。現時点でもサンプル提出のスコアを上回ったのは5名と、特異性や難易度の高さが際立っています。推論タスクの入力・出力のペアから規則性を捉えるAIを作る過去に例の無い形式で、どのような解法が導かれるかに注目が集まっています。</p></h3>
<hr>
<p>
<strong style='display: block;'><a href="https://arxiv.org/abs/2002.05687?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">[2002.05687] Tree-SNE: Hierarchical Clustering and Visualization Using t-SNE</a></strong>

</p>
<p><p>t-SNE &amp; 階層的クラスタリング。<a href="https://github.com/isaacrob/treesne" target="_blank">GitHub</a>でコードも公開済ですが、導入にはC++のコンパイルが必要で、多少の手間がかかりそうです。</p></p>
<p>
<img width="140" height="140" alt="機械学習研究者＆エンジニアが頭を抱える実験管理に役立つツールを比較した - のんびりしているエンジニアの日記" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/562/911/thumb/20200215195943.png?1581924359" />
<strong style='display: block;'><a href="http://nonbiri-tereka.hatenablog.com/entry/2020/02/17/090613?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">機械学習研究者＆エンジニアが頭を抱える実験管理に役立つツールを比較した - のんびりしているエンジニアの日記</a> &mdash; <a href="http://nonbiri-tereka.hatenablog.com/entry/2020/02/17/090613">nonbiri-tereka.hatenablog.com</a></strong>
皆さんこんにちは。 お元気でしょうか。GoogleQA20thで悔しいけど楽しかったです。 自然言語処理のみのコンペを真面目に挑んだのは初で、勉強になることが多かったです。 今回は実験管理ツールの紹介と比較をします。 特徴がわかる範囲で簡単に実装も書いているので、参考にしてみてください。 実験管理ツール 実験管理の必要性 実験管理ツールの要件 実験管理ツールの紹介 Excel Excelとは 良い点 欠点 mag magとは サンプル実装 良い点 ここが少し残念 Weights and Biases Weights and Biasesとは サンプル実装 良い点 ここが少し残念 MLFlow …
</p>
<div style='clear: both;'></div>
<p><p>機械学習の実験管理ツールの紹介と比較。「Excel」「mag」「Weights and Biases」「MLFlow」を、出力の保存や結果の可視化UIなど複数の観点でまとめています。</p></p>
<p>
<img width="140" height="140" alt="Label Smoothing &amp; Deep Learning: Google Brain explains why it works and when to use (SOTA tips)" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/567/172/thumb/1*JrWCSzS73MA__5YeKJ7H1g.jpeg?1581990942" />
<strong style='display: block;'><a href="https://medium.com/@lessw/label-smoothing-deep-learning-google-brain-explains-why-it-works-and-when-to-use-sota-tips-977733ef020?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Label Smoothing &amp; Deep Learning: Google Brain explains why it works and when to use (SOTA tips)</a> &mdash; <a href="https://medium.com/@lessw/label-smoothing-deep-learning-google-brain-explains-why-it-works-and-when-to-use-sota-tips-977733ef020">medium.com</a></strong>
Hinton, Muller and Cornblith from Google Brain released a new paper titled “When does label smoothing help?” and dive deep into the internals of how label smoothing affects the final activation…
</p>
<div style='clear: both;'></div>
<p><p>Google Brainから出た「When Does Label Smoothing Help?」の解説記事。Label Smoothingが最終層にどういう影響を与えるか可視化して議論しています。</p></p>
<p>
<strong style='display: block;'><a href="https://www.sciencedirect.com/science/article/pii/S0169207019301876?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Forecasting in social settings: The state of the art - ScienceDirect</a></strong>

</p>
<p><p>3月にKaggle上でのコンペ開催が予告されているWalmart社の論文。各種の予測手法や、前回開催したコンペの振り返りなどが掲載されています。</p></p>
<p>
<img width="140" height="140" alt="学習済み日本語word2vecとその評価について - 株式会社ホクソエムのブログ" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/576/083/thumb/McqbhJv.png?1582163244" />
<strong style='display: block;'><a href="https://blog.hoxo-m.com/entry/2020/02/20/090000?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">学習済み日本語word2vecとその評価について - 株式会社ホクソエムのブログ</a> &mdash; <a href="https://blog.hoxo-m.com/entry/2020/02/20/090000">blog.hoxo-m.com</a></strong>
ホクソエムサポーターの白井です。 今回は日本語の word2vec に着目し、日本語の学習済み word2vec の評価方法について紹介します。 自然言語は非構造化データであるため、単語や文章を計算機で扱いやすい表現に変換する必要があります。 そのための方法の1つに word2vec があり、Bag of Words (BoW) や tf-idf とならんでよく用いられます。 一般に、word2vec は Mikolovが提案した手法 (CBOW, Skip-gram) をはじめ、 GloVe や fastText など、単語をベクトルで表現する単語分散表現のことを指します。 word2vec…
</p>
<div style='clear: both;'></div>
<p><p>複数の学習済み日本語word2vecモデルを日本語のデータセットで評価。<a href="https://github.com/shihono/evaluate_japanese_w2v" target="_blank">GitHub</a>でコードも公開されています。</p></p>
<p>
<strong style='display: block;'><a href="https://qiita.com/mkt3/items/b41dcf0185e5873f5f75?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">大規模日本語ビジネスニュースコーパスを学習したALBERT（MeCab+Sentencepiece利用）モデルの紹介 - Qiita</a></strong>

</p>
<p><p>大規模日本語ビジネスニュースコーパスで学習した「ALBERT（MeCab+Sentencepiece利用）」モデルを公開。ALBERTは精度を保持しながらBERTを軽量化したモデルで、実用面での使い勝手が高い印象です。</p></p>
<p>
<strong style='display: block;'><a href="https://www.youtube.com/watch?feature=youtu.be&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter&amp;v=05qlCP-xL9Y">様々な CNN #3～複数の解像度を扱う～ Deep Learning精度向上テクニック</a></strong>
この動画では、複数の解像度を扱うことで高い性能を実現するCNNのアーキテクチャ、U-Net、Stacked Hourglass Network、Feature Pyramid Network（FPN）、Multi-Level Feature Pyramid Network（MLFPN）、High-Resoluti...
</p>
<p><p>Deep Learningを用いた画像関連タスクの精度向上の手法を、単純なCNNが持つ課題に紐づく形で解説。「U-Net」「Hourglass」「FPN」「MLFPN」「HRNet」など、複数の解像度を扱うことで高い性能を実現するCNNのアーキテクチャを紹介しています。</p></p>
<p>
<img width="140" height="140" alt="【論文メモ】Self-training with Noisy Student improves ImageNet classification - u++の備忘録" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/568/424/thumb/20200218124212.png?1582018526" />
<strong style='display: block;'><a href="https://upura.hatenablog.com/entry/2020/02/18/180500?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">【論文メモ】Self-training with Noisy Student improves ImageNet classification - u++の備忘録</a> &mdash; <a href="https://upura.hatenablog.com/entry/2020/02/18/180500">upura.hatenablog.com</a></strong>
twitterで流れてきたGoogleの論文が、最近のKaggleでも頻繁に使われる「Pseudo Labeling」を拡張した興味深いものでした。本記事では、簡単にこの論文を紹介します。 Last week we released the checkpoints for SOTA ImageNet models trained by NoisyStudent. Due to popular demand, we’ve also opensourced an implementation of NoisyStudent. The code uses SVHN for demonstration…
</p>
<div style='clear: both;'></div>
<p><p>最近のKaggleで頻繁に使われる「Pseudo Labeling」を拡張したGoogleの論文を解説。ベルを予測したtestデータをtrainデータに追加する際にノイズを付与することで頑健性を高める工夫があります。</p></p>
