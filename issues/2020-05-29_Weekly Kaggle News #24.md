# Weekly Kaggle News #24
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-24-250953
<h3><h2>News</h2><p>Kaggle Grandmasterの<a href="https://www.kaggle.com/confirm" target="_blank">smly</a>さんは23日、画像・NLPコンペを題材としたKaggle関連本を共著で執筆していると明らかにしました。『<a href="https://www.kspub.co.jp/book/detail/5190067.html" target="_blank">PythonではじめるKaggleスタートブック</a>』と同じく、講談社から出版される予定とのことです。<a href="https://www.kaggle.com/tkm2261" target="_blank">tkm2261さん</a>のKagglerインタビュー企画「kagglerを訪ねて三千里」の第3弾にゲスト出演した際に<a href="https://youtu.be/BSvP60BzoOc" target="_blank">公表しました</a>。次回30日のゲストはKaggle Grandmasterの<a href="https://www.kaggle.com/rsakata" target="_blank">Jackさん</a>で、<a href="https://docs.google.com/forms/d/e/1FAIpQLSeCHH9iJyjdeZAGhklBqODIyw-kNgsFE3kp4Noy7gd0zziqFA/viewform" target="_blank">質問</a>も募集されています。</p><h2>Competitions</h2><p>Kaggle「<a href="https://www.kaggle.com/c/siim-isic-melanoma-classification" target="_blank">SIIM-ISIC Melanoma Classification</a>」コンペが27日に始まりました。皮膚がんの一種「Melanoma」を皮膚の画像から判断するタスクで、評価指標はAUCです。</p><p>イオンチャネルの開閉状態を予測するKaggle「<a href="https://www.kaggle.com/c/liverpool-ion-switching" target="_blank">University of Liverpool - Ion Switching</a>」コンペが25日に終わりました。1位チームが2位以下と0.03近くの差を付けたことに、<a href="https://www.kaggle.com/c/liverpool-ion-switching/discussion/153689" target="_blank">驚きの声</a>が挙がっています。上位チームの投稿によると、test dataに関する「リーク」があったそうです（<a href="https://www.kaggle.com/c/liverpool-ion-switching/discussion/153940" target="_blank">1位</a>、<a href="https://www.kaggle.com/c/liverpool-ion-switching/discussion/153991" target="_blank">2位</a>、<a href="https://www.kaggle.com/c/liverpool-ion-switching/discussion/153824" target="_blank">3位</a>）。</p><p>論理パズルが題材のKaggle「<a href="https://www.kaggle.com/c/abstraction-and-reasoning-challenge" target="_blank">Abstraction and Reasoning Challenge</a>」コンペが27日に終了しました。推論タスクの入力・出力のペアから規則性を捉えるコンペで、過去に例の無い形式として注目を集めていました。</p><p>全米大学体育協会（NCAA）バスケットボールトーナメントのデータ分析レポートで争うKaggle「<a href="https://www.kaggle.com/c/march-madness-analytics-2020" target="_blank">Google Cloud &amp; NCAA® March Madness Analytics</a>」コンペの<a href="https://www.kaggle.com/c/march-madness-analytics-2020/discussion/152203" target="_blank">結果が発表</a>されました。勝敗結果を予測するコンペは、新型コロナウイルス感染症の影響で中止となっています。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="白金鉱業.FM on Twitter: &quot;🎙#白金鉱業fm #28＆29 UPDATE🎙 カリフォルニア大学 博士課程でMachine Learning Securityの研究をされている @tkm2261 さん特別ゲスト回！ 前編ではtakamiさんの研究分野や海外留学について、後編はKagglerコミュニティーについてお話をしました👨‍💻 https://t.co/J6hOzxZrW7 https://t.co/SJxPY8GX5v… https://t.co/DnkMOkva9i&quot;" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/015/107/thumb/EY0aaQcUYAACLZf.png_large?1590383125" />
<strong style='display: block;'><a href="https://twitter.com/shirokane_fm/status/1264696256636448769?s=20&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">白金鉱業.FM on Twitter: &quot;🎙#白金鉱業fm #28＆29 UPDATE🎙 カリフォルニア大学 博士課程でMachine Learning Securityの研究をされている @tkm2261 さん特別ゲスト回！ 前編ではtakamiさんの研究分野や海外留学について、後編はKagglerコミュニティーについてお話をしました👨‍💻 https://t.co/J6hOzxZrW7 https://t.co/SJxPY8GX5v… https://t.co/DnkMOkva9i&quot;</a> &mdash; <a href="https://twitter.com/shirokane_fm/status/1264696256636448769?s=20">twitter.com</a></strong>

</p>
<div style='clear: both;'></div>
<p><p>「kagglerを訪ねて三千里」と題した日本人Kagglerインタビュー企画も実施中の<a href="https://www.kaggle.com/tkm2261" target="_blank">tkm2261さん</a>をゲストに迎えたPodcast。カリフォルニア大学博士課程での研究内容やkaggler-jaコミュニティについての話題が展開されています。</p></p>
<p>
<img width="140" height="140" alt="Kaggle Days Shop" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/032/356/thumb/kaggledays_final_logo-800_3.png?1590656917" />
<strong style='display: block;'><a href="https://kaggle-days-shop.myshopify.com/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Kaggle Days Shop</a> &mdash; <a href="https://kaggle-days-shop.myshopify.com/">kaggle-days-shop.myshopify.com</a></strong>
https://kaggledays.com/
</p>
<div style='clear: both;'></div>
<p><p>Kaggle公式イベント「Kaggle Days」に関するオンラインショップが開設されました。マグカップやTシャツなどが販売されています。</p></p>
<p>
<img width="140" height="140" alt="画像認識と深層学習" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/008/421/thumb/deeplearningforimagerecognition-200522001239-thumbnail-4.jpg?1590174455" />
<strong style='display: block;'><a href="https://www.slideshare.net/ren4yu/ss-234439652?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">画像認識と深層学習</a> &mdash; <a href="https://www.slideshare.net/ren4yu/ss-234439652">www.slideshare.net</a></strong>
日本ロボット学会 ロボット工学セミナー 第126回 ロボットのための画像処理技術 講演資料 https://www.rsj.or.jp/event/seminar/news/2020/s126.html 2012年の画像認識コンペティションILSVRCにおけるAlexNetの登場以降，画像認識においては深層学習，その…
</p>
<div style='clear: both;'></div>
<p><p>画像認識のための深層学習についてのサーベイ資料。画像分類コンペにおけるモデルアーキテクチャの歴史や、高速化の手法などを紹介しています。</p></p>
<p>
<img width="140" height="140" alt="社内輪講資料「semi-supervised learning かじってみた」 - Speaker Deck" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/008/427/thumb/slide_0.jpg?1590174576" />
<strong style='display: block;'><a href="https://speakerdeck.com/takarasawa_/she-nei-lun-jiang-zi-liao-semi-supervised-learning-kazitutemita?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">社内輪講資料「semi-supervised learning かじってみた」 - Speaker Deck</a> &mdash; <a href="https://speakerdeck.com/takarasawa_/she-nei-lun-jiang-zi-liao-semi-supervised-learning-kazitutemita">speakerdeck.com</a></strong>

</p>
<div style='clear: both;'></div>
<p><p>semi-supervised learningについてのサーベイ資料。論文「<a href="https://link.springer.com/article/10.1007/s10994-019-05855-6" target="_blank">A survey on semi-supervised learning</a>」の内容をスライド形式にまとめています。</p></p>
<p>
<img width="140" height="140" alt="AI開発の新たな手法「データサイエンスコンペティション」とは？｜Nishika株式会社｜note" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/008/453/thumb/rectangle_large_type_2_0f960366a8f3d60bc0f5965c3ae821be.png?1590175082" />
<strong style='display: block;'><a href="https://note.com/nishika_inc/n/n473a6c4a6a07?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">AI開発の新たな手法「データサイエンスコンペティション」とは？｜Nishika株式会社｜note</a> &mdash; <a href="https://note.com/nishika_inc/n/n473a6c4a6a07">note.com</a></strong>
 こんにちは。NishikaのCTOを務めております松田と申します。  弊社サービスの中でも、幹となるサービスは データサイエンスコンペティションです。 それって何？何が良いの？という疑問をお持ちのビジネスパーソンの皆様 向けに、本記事でご紹介したいと思います。   データサイエンスコンペティションとは？  データサイエンスコンペティションを一言で説明すると、 数百名以上のデータサイエンティストがAIモデルの精度を競い合い、 最も精度の高かったモデルを賞金と引き換えにホスト企業が受け取る ものです。  具体的には、以下の３ステップで行われます。     実はこのデータサイエンスコンペと
</p>
<div style='clear: both;'></div>
<p><p>コンペプラットフォームを運営するNishikaによる「データサイエンスコンペ」の紹介記事。運営の観点で、コンペのメリットや情報保護の観点での懸念などを述べています。</p></p>
<p>
<img width="140" height="140" alt="Nishika「財務・非財務情報を活用した株主価値予測」コンペ2位でした - u++の備忘録" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/037/132/thumb/20200528191049.png?1590712838" />
<strong style='display: block;'><a href="https://upura.hatenablog.com/entry/2020/05/28/220300?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Nishika「財務・非財務情報を活用した株主価値予測」コンペ2位でした - u++の備忘録</a> &mdash; <a href="https://upura.hatenablog.com/entry/2020/05/28/220300">upura.hatenablog.com</a></strong>
Nishikaで開催されていた「財務・非財務情報を活用した株主価値予測」コンペ*1で、2位になりました。 オープンデータのコンペなので、pipelineを整備しながら、のんびりと取り組みました。最終的にはLightGBMとCatBoostで3種類の予測値（public 19位, 19位, 36位相当）を作り、Netflix blending*2で、public 2位、private 3位になりました。その後の最終成果物の確認で1位だった方が辞退したため、2位で順位確定しました。 ソースコードはGitHub*3で公開しています。 *1:www.nishika.com *2:upura.haten…
</p>
<div style='clear: both;'></div>
<p><p>Nishikaで開催されていた「財務・非財務情報を活用した株主価値予測」コンペの2位解法。関連記事としてアンサンブル手法「Netflix blending」も解説しています。ソースコードもGitHubで公開しました。</p></p>
<p>
<img width="140" height="140" alt="確率予測とCalibrationについて - 機械学習 Memo φ(・ω・ )" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/012/324/thumb/20200523134440.png?1590300060" />
<strong style='display: block;'><a href="https://yukoishizaki.hatenablog.com/entry/2020/05/24/145155?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">確率予測とCalibrationについて - 機械学習 Memo φ(・ω・ )</a> &mdash; <a href="https://yukoishizaki.hatenablog.com/entry/2020/05/24/145155">yukoishizaki.hatenablog.com</a></strong>
概要 確率予測とCalibration(キャリブレーション)に関する勉強会に参加したので、学んだことの一部と、自分で調べてみたことについてまとめました。 概要 Calibrationとは Calibration Curve Calibrationの方法 Sigmoid / Platt Scale Isotonic Regression 確率予測に使われる評価指標 Brier Score ECE コード 不均衡データに対するCalibration LightGBMにCalibrationは不要か NNにCalibrationは不要か 終わり techplay.jp勉強会で使われていた言葉を、自分…
</p>
<div style='clear: both;'></div>
<p><p>オンライン勉強会「機械学習の分類と確率予測って何が違うの？疑問を解決しよう」を受けてのまとめ記事。分類モデルの出力値を補正する「Calibration」に関する勉強会でした。<a href="https://youtu.be/a3lSojx_37M" target="_blank">アーカイブ動画</a>も閲覧可能です。</p></p>
<p>
<img width="140" height="140" alt="Self-supervised learning: The plan to make deep learning data-efficient – TechTalks" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/014/249/thumb/gradient-descent-deep-learning.jpg?1590350792" />
<strong style='display: block;'><a href="https://bdtechtalks.com/2020/03/23/yann-lecun-self-supervised-learning/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Self-supervised learning: The plan to make deep learning data-efficient – TechTalks</a> &mdash; <a href="https://bdtechtalks.com/2020/03/23/yann-lecun-self-supervised-learning/">bdtechtalks.com</a></strong>
At the AAAI 2020 ConferenceDeep learning pioneer Yann LeCun discussed the problems of supervised learning and possible solutions to make AI less data-hungry.
</p>
<div style='clear: both;'></div>
<p><p>「AAAI 2020」でのself-supervised learningに関するYann LeCunさんの講演の要約記事。NLP分野ではBERTに代表されるTransformers群が一定の成果を挙げている領域について、現在のdeep learning研究が抱える課題を議論しつつ展望を述べています。</p></p>
<p>
<img width="140" height="140" alt="PyTorch XLAでTPUを操作する - のんびりしているエンジニアの日記" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/020/932/thumb/20200330235102.png?1590449830" />
<strong style='display: block;'><a href="https://nonbiri-tereka.hatenablog.com/entry/2020/05/26/082922?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">PyTorch XLAでTPUを操作する - のんびりしているエンジニアの日記</a> &mdash; <a href="https://nonbiri-tereka.hatenablog.com/entry/2020/05/26/082922">nonbiri-tereka.hatenablog.com</a></strong>
皆さんこんにちは お元気でしょうか。最近は宅配スーパーによりますます外出しなくなっています。本日はTPUをPyTorchで使ってみます。 GPUと比較して、TPUは汎用性をなくした代わりによりDeepLearningに必要な演算を高速にできるようにしたものです。 Why TPU? TPUとは？ どの程度高速なのか どうやって使うのか PyTorch-XLA 準備 インストール 実装 インストール部 結果可視化 学習 最後に Why TPU? TPUとは？ TPUはニューラルネットワークの演算専用のアーキテクチャです。 一言で使うモチベーションをお伝えするのであれば「速いから」の一言です 他の用…
</p>
<div style='clear: both;'></div>
<p><p>TPUをPyTorchで使うためのライブラリ「PyTorch-XLA」に関する記事。簡単な使い方や所感がまとめられています。</p></p>
<p>
<img width="140" height="140" alt="NLTKを使った英語テキストのtokenize - エイエイレトリック" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/026/293/thumb/51EoFqAGo1L._SL160_.jpg?1590553251" />
<strong style='display: block;'><a href="https://eieito.hatenablog.com/entry/2020/05/27/100000?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">NLTKを使った英語テキストのtokenize - エイエイレトリック</a> &mdash; <a href="https://eieito.hatenablog.com/entry/2020/05/27/100000">eieito.hatenablog.com</a></strong>
英語のtokenizeは日本語の分かち書きに比べたら楽なようにみえるが、注意すべき点があるよという紹介をします。 そのために、今回は NLTK (Natural Language Toolkit) を使ってtokenizeします。 (NLTK のVersion 3.5、Python 3.7.4で動作確認しています。) ちなみにtokenizeは日本語に翻訳すると "トークン化する" ですが、NLTK の関数名と統一するためにtokenizeと表記します。 文のtokenize sent_tokenize 単語のtokenize word_tokenize TreebankWordTokeniz…
</p>
<div style='clear: both;'></div>
<p><p>NLTKライブラリを用いた英語テキストの文分割・単語分割について扱った記事。スペースだけでは区切れない場合など、細かく解析しています。日本語テキストの文区切りについては、<a href="https://qiita.com/wwwcojp/items/3535985007aa4269009c" target="_blank">こちらの記事</a>が参考になりました。</p></p>
<p>
<img width="140" height="140" alt="How Kaggle built and deployed a spam filter in 8 days using AutoML | Google Cloud Blog" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/032/210/thumb/GCP_Twitter_Card-2000_C3_971000.png?1590654223" />
<strong style='display: block;'><a href="https://cloud.google.com/blog/products/ai-machine-learning/how-kaggle-solved-a-spam-problem-using-automl?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">How Kaggle built and deployed a spam filter in 8 days using AutoML | Google Cloud Blog</a> &mdash; <a href="https://cloud.google.com/blog/products/ai-machine-learning/how-kaggle-solved-a-spam-problem-using-automl">cloud.google.com</a></strong>
With AutoML Natural Language on Google Cloud, Kaggle deployed a spam detection model to production in just eight days.
</p>
<div style='clear: both;'></div>
<p><p>Kaggleの中の人が、Kaggle上のスパムアカウント検知のためにAutoMLを活用した話。不適切なプロフィールのアカウントを検知するシステムを構築すべく、自然言語処理APIを利用して8日間でデプロイまで展開したとのことです。</p></p>
