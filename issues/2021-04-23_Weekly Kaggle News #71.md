# Weekly Kaggle News #71
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-71-564448
<h3><h2>News</h2><p>「<a href="https://huggingface.co/transformers/" target="_blank">Transformers</a>」など最先端の自然言語処理ライブラリを開発しているHugging Faceから、新しいライブラリ「<a href="https://huggingface.co/blog/accelerate-library" target="_blank">Accelerate</a>」が公開されました。深層学習ライブラリ「PyTorch」のコードにおけるCPUとGPUのやり取りなどを処理します。21日には、同社提供のライブラリ「<a href="https://huggingface.co/autonlp" target="_blank">AutoNLP</a>」が<a href="https://twitter.com/abhi1thakur/status/1384875565761679360?s=20" target="_blank">日本語に対応</a>しました。</p><p>KaggleのNotebooks環境で使われているDocker imageの<a href="https://github.com/Kaggle/docker-python/releases/tag/046f8514e4f3f41fef443911ead054414479ea948e2c0fb074114d43daedd794" target="_blank">最新版</a>が20日に公開されました。GPU版では「<a href="https://developer.nvidia.com/cuda-toolkit" target="_blank">CUDA</a>」のバージョンが11に更新されています。</p><p>Kaggleは17日、既存の「Favorites」機能を「Bookmarks」機能に置き換えていく<a href="https://www.kaggle.com/product-feedback/233062" target="_blank">方針</a>を示しました。今後数週間で段階的にリリースしていく予定になっています。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="Flashlight: Fast and flexible machine learning in C++" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/008/949/301/thumb/174124898_3674817559294231_7082232024470124786_n.png?1619153310" />
<strong style='display: block;'><a href="https://ai.facebook.com/blog/flashlight-fast-and-flexible-machine-learning-in-c-plus-plus/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Flashlight: Fast and flexible machine learning in C++</a> &mdash; <a href="https://ai.facebook.com/blog/flashlight-fast-and-flexible-machine-learning-in-c-plus-plus/">ai.facebook.com</a></strong>
<p>Deep and machine learning (ML) frameworks are good at what they do, but altering their underlying code is typically difficult.</p>
</p>
<div style='clear: both;'></div>
<p><p>Facebookは16日、C++の深層学習ライブラリ「<a href="https://ai.facebook.com/blog/flashlight-fast-and-flexible-machine-learning-in-c-plus-plus/" target="_blank">Flashlight</a>」を公開しました。同社の音声認識プロジェクトなどでの利用実績があるそうです。</p></p>
<p>
<img width="140" height="140" alt="CS224W: Machine Learning with Graphs" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/008/874/933/thumb/hqdefault.jpg?1618742486" />
<strong style='display: block;'><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">CS224W: Machine Learning with Graphs</a> &mdash; <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn">www.youtube.com</a></strong>
Share your videos with friends, family, and the world
</p>
<div style='clear: both;'></div>
<p><p>スタンフォード大学で2021年1〜3月に開講された「<a href="http://web.stanford.edu/class/cs224w/" target="_blank">Machine Learning with Graphs</a>」の講義動画。埋め込み表現やニューラルネットワークに関する話題が盛り込まれています。</p></p>
<p>
<img width="140" height="140" alt="Google Colab上で秘匿情報を安全に使うために、Google Cloud Secret Managerを使う" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/008/864/321/thumb/new_txlqub.png?1618652381" />
<strong style='display: block;'><a href="https://zenn.dev/hattan0523/articles/9be93149ac0754?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Google Colab上で秘匿情報を安全に使うために、Google Cloud Secret Managerを使う</a> &mdash; <a href="https://zenn.dev/hattan0523/articles/9be93149ac0754">zenn.dev</a></strong>

</p>
<div style='clear: both;'></div>
<p><p>Google Colaboratoryから、Google Cloud Secret Managerに登録したAPIキーを呼び出して使う方法の紹介記事。公にできない値を管理するための一つの手段です。</p></p>
<p>
<img width="140" height="140" alt="全日本CV勉強会発表資料 Learning Transformer in 40 Minutes - Speaker Deck" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/008/874/938/thumb/slide_0.jpg?1618742546" />
<strong style='display: block;'><a href="https://speakerdeck.com/sei88888/quan-ri-ben-cvmian-qiang-hui-fa-biao-zi-liao-learning-transformer-in-40-minutes?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">全日本CV勉強会発表資料 Learning Transformer in 40 Minutes - Speaker Deck</a> &mdash; <a href="https://speakerdeck.com/sei88888/quan-ri-ben-cvmian-qiang-hui-fa-biao-zi-liao-learning-transformer-in-40-minutes">speakerdeck.com</a></strong>
<p>cvpaper.challengeのメンバーとして全日本コンピュータビジョン勉強会で発表を行った時の発表資料（前編）です。 </p>
</p>
<div style='clear: both;'></div>
<p><p>画像領域における「Transformer」を題材にした「<a href="https://kantocv.connpass.com/event/205271/" target="_blank">第六回　全日本コンピュータビジョン勉強会</a>」の勉強資料。公開されている発表資料などは<a href="https://togetter.com/li/1700720" target="_blank">ハッシュタグ #japancv</a> で確認できます。</p></p>
<p>
<strong style='display: block;'><a href="https://qiita.com/omiita/items/0c2176a1edc26d69e2c9?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">帰ってきたResNet！最新の画像認識モデル「ResNet-RS」を解説！ - Qiita</a></strong>
<p>今回紹介する論文は、<strong>学習方法</strong>と<strong>スケールアップ方法</strong>を工夫することでResNetをSoTAレベルの性能にまで向上させています。</p>
</p>
<p><p>画像認識分野で著名な「ResNet」に工夫を加えた「<a href="https://arxiv.org/abs/2103.07579" target="_blank">ResNet-RS</a>」の解説記事。<strong>学習手法などの改善を積み重ね、性能を高めています。</strong></p></p>
