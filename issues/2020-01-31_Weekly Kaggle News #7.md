# Weekly Kaggle News #7
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-7-222868
<h3><h2>News</h2><p>Kaggle「<a href="https://www.kaggle.com/c/petfinder-adoption-prediction?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">PetFinder.my Adoption Prediction</a>」コンペで失格になった1位チームは、賞金$10,000を返金しました。この<a href="https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/125436#731014" target="_blank">賞金はPetFinder.my社のAI開発プロジェクトに活用される</a>とのことです。問題の背景や発覚の経緯などは<a href="https://medium.com/@u39kun/how-a-top-kaggle-grandmaster-cheated-and-got-permanently-banned-c86ca431f499?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">こちら</a>のブログ記事にまとまっています。</p><p>2019年12月11、12日に開催された「<a href="https://kaggledays.com/tokyo/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">Kaggle Days Tokyo</a>」の<a href="https://youtu.be/HTcM03FeLSs" target="_blank">総活動画</a>が27日に公開されました。<a href="https://www.youtube.com/user/kaggledotcom/videos" target="_blank">1日目のプレゼンテーション動画</a>も徐々に投稿されています。2日目のオフラインコンペにデータ提供した日本経済新聞社による<a href="https://hack.nikkei.com/blog/report_kaggle_days_tokyo/" target="_blank">開催報告記事</a>も公開されました。</p><p>テーブルデータに取り組む際に必須の<a href="https://pandas.pydata.org/pandas-docs/version/1.0/whatsnew/v1.0.0.html" target="_blank">「Pandas」の1.0.0版</a>が30日に正式リリースされました。整数での欠損値を示す型の追加、apply時の処理が高速になるNumbaの利用など、いくつかの更新があります。<a href="https://dev.pandas.io/pandas-blog/pandas-10.html" target="_blank">これまでの過程を振り返る公式ブログ</a>も公開されました。<a href="https://qiita.com/simonritchie/items/e28c52211890fef33810?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">日本語の解説記事</a>も出ています。</p><p><strong>Competitions</strong></p><p>先週3つのKaggleコンペが終わり、メダルが獲得できるコンペが「<a href="https://www.kaggle.com/c/google-quest-challenge" target="_blank">Google QUEST Q&amp;A Labeling</a>」「<a href="https://www.kaggle.com/c/bengaliai-cv19" target="_blank">Bengali.AI Handwritten Grapheme Classification</a>」「<a href="https://www.kaggle.com/c/deepfake-detection-challenge" target="_blank">Deepfake Detection Challenge</a>」の3つのみとなりました。</p><p>23日に終了した子供向けゲームのアクセスログを分析する「<a href="https://www.kaggle.com/c/data-science-bowl-2019?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">2019 Data Science Bowl</a>」コンペでは、上位解法が出揃い、日本語のまとめ記事も公開されています（<a href="https://naotaka1128.hatenadiary.jp/entry/dsb-2019-top-solution" target="_blank">記事1</a>, <a href="https://takaishikawa42.hatenablog.com/entry/2020/01/29/090852" target="_blank">記事2</a>）。<a href="https://www.kaggle.com/limerobot/dsb2019-v77-tr-dt-aug0-5-3tta?scriptVersionId=27487984" target="_blank">3位解法</a>は、自然言語処理分野で多く用いられているtransformerモデルでした。テーブルデータを扱う場合も、系列の特徴を捉えるモデルの活用事例が目立ち始めています。</p><p>7日に最終結果が判明したアメフトのプレイデータを用いた「<a href="https://www.kaggle.com/c/nfl-big-data-bowl-2020?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">NFL Big Data Bowl</a>」コンペについて28日、<a href="https://operations.nfl.com/stats-central/stats-articles/what-the-top-predictions-looked-like-in-the-nfls-big-data-bowl/" target="_blank">NFLの公式サイト</a>で1位チーム「The Zoo」の取り組みが紹介されました。27日には、Kagglerによる<a href="https://youtu.be/_Srv0bKmfjY" target="_blank">インタビュー動画</a>も公開され、The Zooの2人のKaggleへの取り組み方や同コンペの解法が語られています。</p><p>atma株式会社とサイバーエージェントAI事業本部は25日、学生以外も参加できるオフラインコンペ「<a href="https://atma.connpass.com/event/161251/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">CA × atmaCup</a>」を東京・大阪で同時開催しました。Kaggle Grandmaster、Masterらを含む数多くの参加者が集まりました（<a href="http://nonbiri-tereka.hatenablog.com/entry/2020/01/28/081802" target="_blank">参加者のブログ記事</a>）。atmaCupは過去3回開催されており、東京との同時開催は今回が初めてでした。</p><h2>Dataset</h2><p><a href="https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset" target="_blank">新型のコロナウイルスによる肺炎に関するデータセット</a>がKaggle Datasetsとして投稿されました。1月22日以降の罹患者数・死亡者数などが格納されています。Kaggleで2019年11月に「Datasets」の称号を追加しており、コンペだけではないデータサイエンスプラットフォームとしての立ち位置を強めているように感じます。</p><h2>PR</h2><p>Kaggle入門書『<a href="https://www.amazon.co.jp/dp/4065190061" target="_blank">PythonではじめるKaggleスタートブック</a>』のAmazon予約が始まりました。<a href="https://qiita.com/upura/items/3c10ff6fed4e7c3d70f0" target="_blank">Qiitaで公開しているKaggle入門記事</a>を基に執筆しました。同人誌ながら累計2500部以上を売り上げている『<a href="https://note.com/currypurin/n/nf390914c721e" target="_blank">Kaggleのチュートリアル</a>』を執筆したカレーさんとの共著です。詳細は<a href="https://upura.hatenablog.com/entry/2019/12/04/220200" target="_blank">筆者のブログ</a>をご覧ください。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="半教師あり学習自分用にメモ - ココアのお勉強ブログ" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/464/689/thumb/qdrJjB3.png?1579843574" />
<strong style='display: block;'><a href="https://hotcocoastudy.hatenablog.jp/entry/2020/01/23/210357?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">半教師あり学習自分用にメモ - ココアのお勉強ブログ</a> &mdash; <a href="https://hotcocoastudy.hatenablog.jp/entry/2020/01/23/210357">hotcocoastudy.hatenablog.jp</a></strong>
半教師あり学習について調べようと思ったので、初歩的な手法としてTemporal ensembling、Mean teachers、MixMatchについて調べました。 間違いがあったら教えてください。 そもそも半教師あり学習って何？ Temporal Ensembling for Semi-Supervised Learning Π-model TEMPORAL ENSEMBLING Mean teachers are better role models:Weight-averaged consistency targets improve semi-supervised deep lear…
</p>
<div style='clear: both;'></div>
<p><p>半教師あり学習のいくつかの手法についてのまとめ記事。「Temporal ensembling」「Mean teachers」「Unsupervised Data Augmentation（UDA）」「MixMatch」を紹介しています。</p></p>
<p>
<img width="140" height="140" alt="1枚しかラベルデータがなくても学習できるFixMatch - akira - Medium" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/473/419/thumb/1*5SCSOqvXcrxL-IwZmZaH_g.png?1580057208" />
<strong style='display: block;'><a href="https://medium.com/@akichan_f/1%E6%9E%9A%E3%81%97%E3%81%8B%E3%83%A9%E3%83%99%E3%83%AB%E3%83%87%E3%83%BC%E3%82%BF%E3%81%8C%E3%81%AA%E3%81%8F%E3%81%A6%E3%82%82%E5%AD%A6%E7%BF%92%E3%81%A7%E3%81%8D%E3%82%8Bfixmatch-982275853a88?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">1枚しかラベルデータがなくても学習できるFixMatch - akira - Medium</a> &mdash; <a href="https://medium.com/@akichan_f/1%E6%9E%9A%E3%81%97%E3%81%8B%E3%83%A9%E3%83%99%E3%83%AB%E3%83%87%E3%83%BC%E3%82%BF%E3%81%8C%E3%81%AA%E3%81%8F%E3%81%A6%E3%82%82%E5%AD%A6%E7%BF%92%E3%81%A7%E3%81%8D%E3%82%8Bfixmatch-982275853a88">medium.com</a></strong>
FixMatch等の半教師あり学習の論文では、CIFAR-10など全てのデータにラベルがついているデータセットを使って半教師あり学習用のデータセットを作って評価することが一般的のようです。学習データの一部をそのまま使い、残りの学習データはラベルなしデータとして扱うことで半教師ありの枠組みで評価できるようにします。…
</p>
<div style='clear: both;'></div>
<p><p>21日にarXivに投稿された半教師あり学習の手法「FixMatch」の解説。少量のラベル付きデータでも学習可能で、1データしかない場合もある程度の精度が出ると実験的に示しています。</p></p>
<p>
<img width="140" height="140" alt="機械学習モデルの判断根拠の説明（Ver.2）" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/494/213/thumb/aistaiseminarhara200129-200129055035-thumbnail-4.jpg?1580397975" />
<strong style='display: block;'><a href="https://www.slideshare.net/SatoshiHara3/ver2-225753735?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">機械学習モデルの判断根拠の説明（Ver.2）</a> &mdash; <a href="https://www.slideshare.net/SatoshiHara3/ver2-225753735">www.slideshare.net</a></strong>
【第40回AIセミナー】 「説明できるAI　〜AIはブラックボックスなのか？〜」 https://www.airc.aist.go.jp/seminar_detail/seminar_040.html 【講演タイトル】 機械学習モデルの判断根拠の説明 【講演概要】 本講演では、機械学習モデルの判断根拠を提示するための…
</p>
<div style='clear: both;'></div>
<p><p>原聡助教（大阪大学）による機械学習モデルの説明性に関するまとめスライド。23日には、神嶌敏弘主任研究員（産業技術総合研究所）による<a href="http://ai-elsi.org/wp-content/uploads/2020/01/20200109-fairness_sympo.pdf" target="_blank">機械学習の公平性についての発表資料</a>も公開されました。Kaggleで直接問われることはないですが、説明性や公平性は機械学習を取り巻く重要な話題となっています。</p></p>
<p>
<img width="140" height="140" alt="NGBoost Explained— Comparison to LightGBM and XGBoost" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/496/348/thumb/0*FEzlTL1650XUQ99X?1580435292" />
<strong style='display: block;'><a href="https://towardsdatascience.com/ngboost-explained-comparison-to-lightgbm-and-xgboost-fda510903e53?gi=417d4d77d870&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">NGBoost Explained— Comparison to LightGBM and XGBoost</a> &mdash; <a href="https://towardsdatascience.com/ngboost-explained-comparison-to-lightgbm-and-xgboost-fda510903e53?gi=417d4d77d870">towardsdatascience.com</a></strong>
Stanford ML Group recently published a new algorithm in their paper, [1] Duan et al., 2019 and its implementation called NGBoost. This algorithm includes uncertainty estimation into the gradient…
</p>
<div style='clear: both;'></div>
<p><p>2019年10月に発表され、予測分布も出力できる点などで話題の勾配ブースティング決定木の手法「<a href="https://arxiv.org/abs/1910.03225" target="_blank">NGBoost</a>」の解説記事。Pythonの実装例付きで「LightGBM」や「XGBoost」とも比較しています。</p></p>
<p>
<img width="140" height="140" alt="Kaggle - Winners, Tools and Frameworks, Country wise details, Winners tips" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/496/387/thumb/maxresdefault.jpg?1580436068" />
<strong style='display: block;'><a href="https://www.youtube.com/watch?feature=youtu.be&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter&amp;v=pL96IPZZ-88">Kaggle - Winners, Tools and Frameworks, Country wise details, Winners tips</a> &mdash; <a href="https://www.youtube.com/watch?v=pL96IPZZ-88&amp;feature=youtu.be">www.youtube.com</a></strong>
Kaggle A Year in Review, Winners, Tools and Frameworks, Country wise details, Winners tips. Credits : 1. ML Trainings - http://mltrainings.ru/ 2. ods.ai 3. w...
</p>
<div style='clear: both;'></div>
<p><p>優れた可視化とともに、2019年のKaggleコンペを振り返る動画。勝者・ツール・賞金・国などさまざまな観点で総括しています。</p></p>
