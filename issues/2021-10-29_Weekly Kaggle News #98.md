# Weekly Kaggle News #98
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-98-822196
<h3><h2>News</h2><p>株価の将来の動向予測が題材のKaggle「<a href="https://www.kaggle.com/c/optiver-realized-volatility-prediction" target="_blank">Optiver Realized Volatility Prediction</a>」の最終評価について、2回目の順位更新の結果が日本時間28日に示され、上位チームが軒並み<a href="https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/283843" target="_blank">大きく順位を落とした</a>ことが話題となりました。同コンペでは学習時に将来のデータセットを参照することでモデルの性能を向上できると議論されており、1回目の順位更新後の<a href="https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/278588" target="_blank">1位</a>や<a href="https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/274970" target="_blank">2位</a>のチームが既に解法を共有済みでした。<a href="https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/282791" target="_blank">運営</a>によると今回の順位更新では、1回目に比べ意図的に評価用データセットに大きなノイズを付与し、将来の情報を利用したモデルの性能が劣化するよう調整したそうです。<a href="https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/256725" target="_blank">将来の情報が利用できないコンペ設計を回避していた</a>点、上位チームの解法公開に後追いする形で仕様を変更した点などが批判を浴びています。</p><h2>Competitions</h2><p><a href="https://twitter.com/SansanDSOC/status/1438790089614626821" target="_blank">名刺に関するデータ</a>を題材にした「<a href="https://atma.connpass.com/event/225124/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">Sansan × atmaCup #12</a>」が15〜24日に開催されました。参加者以外も視聴可能な<a href="https://atma.connpass.com/event/229180/" target="_blank">振り返り会</a>が11月4日に開催されます。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="ICCVでGoogle Landmark Retrieval 2021の解法を発表しました - Taste of Tech Topics" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/011/893/186/thumb/20211020221059.png?1634907186" />
<strong style='display: block;'><a href="https://acro-engineer.hatenablog.com/entry/2021/10/22/172917?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">ICCVでGoogle Landmark Retrieval 2021の解法を発表しました - Taste of Tech Topics</a> &mdash; <a href="https://acro-engineer.hatenablog.com/entry/2021/10/22/172917">acro-engineer.hatenablog.com</a></strong>
<p>先週は一週間、自宅からICCVに参加しており、今年は自分もWorkshopで発表しました。</p>
</p>
<div style='clear: both;'></div>
<p><p>「<a href="https://www.kaggle.com/c/landmark-retrieval-2021?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">Google Landmark Retrieval 2021</a>」の5位解法に関する記事。国際学会「ICCV 2021」の傾向にも言及があり、画像処理の文脈での「Transformer」の台頭について述べられています。</p></p>
<p>
<img width="140" height="140" alt="深層学習の不確実性 - Uncertainty in Deep Neural Networks -" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/011/909/150/thumb/random-211022140331-thumbnail-4.jpg?1634953538" />
<strong style='display: block;'><a href="https://www.slideshare.net/ssuser8672d7/uncertainty-in-deep-neural-networks-250505655?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">深層学習の不確実性 - Uncertainty in Deep Neural Networks -</a> &mdash; <a href="https://www.slideshare.net/ssuser8672d7/uncertainty-in-deep-neural-networks-250505655">www.slideshare.net</a></strong>
<p>深層学習における予測の不確実性</p>
</p>
<div style='clear: both;'></div>
<p><p>深層学習における予測の不確実性について、調査論文をまとめた資料。学習用と評価用のデータセットの特性が異なる問題や、アンサンブルの手法などが取り上げられています。</p></p>
<p>
<img width="140" height="140" alt="Deep Learning on a Budget: Does This Startup Outperform Google Colab?" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/011/945/812/thumb/0*gj6lKhqSOI1iujMV?1635120136" />
<strong style='display: block;'><a href="https://towardsdatascience.com/deep-learning-on-a-budget-does-this-startup-outperform-google-colab-22b102827b55?gi=a7c0f4caae7d&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Deep Learning on a Budget: Does This Startup Outperform Google Colab?</a> &mdash; <a href="https://towardsdatascience.com/deep-learning-on-a-budget-does-this-startup-outperform-google-colab-22b102827b55?gi=a7c0f4caae7d">towardsdatascience.com</a></strong>
For Cloud-Based Deep Learning, There are emerging platforms like Gradient and Colab offering free GPU instances. Can Gradient compete with Google Colab?
</p>
<div style='clear: both;'></div>
<p><p>ブラウザ上のPython実行環境「Google Colaboratory」の競合として「<a href="https://gradient.run/" target="_blank">Gradient</a>」を紹介している記事。GPUの性能など、いくつかの観点で比較しています。</p></p>
<p>
<img width="140" height="140" alt="第60回 Machine Learning 15minutes! Broadcast (2021/10/30 14:00〜)" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/011/945/865/thumb/16555d8e4643ffc07aea150c061c11cd.png?1635120609" />
<strong style='display: block;'><a href="https://machine-learning15minutes.connpass.com/event/226110/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">第60回 Machine Learning 15minutes! Broadcast (2021/10/30 14:00〜)</a> &mdash; <a href="https://machine-learning15minutes.connpass.com/event/226110/">machine-learning15minutes.connpass.com</a></strong>
<p>【イベント参加にあたって】 コロナが落ちつくまでMachine Learning 15minutes!はZoom配信で行います！！</p>
</p>
<div style='clear: both;'></div>
<p><p>30日開催のイベントで「KaggleのゲームAI世界大会で1位になった話」の題目の発表が予定されています。「<a href="https://www.kaggle.com/c/hungry-geese" target="_blank">Hungry Geese</a>」の優勝解法が共有されるようです。</p></p>
<p>
<img width="140" height="140" alt="Software Design 2021年11月号「Kaggleで知る機械学習」を寄稿しました | フューチャー技術ブログ" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/011/969/994/thumb/642111.jpeg?1635229890" />
<strong style='display: block;'><a href="https://future-architect.github.io/articles/20211026b/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Software Design 2021年11月号「Kaggleで知る機械学習」を寄稿しました | フューチャー技術ブログ</a> &mdash; <a href="https://future-architect.github.io/articles/20211026b/">future-architect.github.io</a></strong>
<p>先日10月18日に発売されたSoftware Design 2021年11月号の第一特集、「Kaggleで知る機械学習 前処理から学習モデルの構築，スコアの上げ方までわかる」をフューチャーの農見、玉木、金子が担当しました。</p>
</p>
<div style='clear: both;'></div>
<p><p>18日に発売された『<a href="https://gihyo.jp/magazine/SD/archive/2021/202111" target="_blank">Software Design 2021年11月号</a>』の特集「Kaggleで知る機械学習 前処理から学習モデルの構築，スコアの上げ方までわかる」の著者による紹介記事。感想を記載した<a href="https://upura.hatenablog.com/entry/2021/10/22/200707" target="_blank">記事</a>も公開しました。</p></p>
<p>
<img width="140" height="140" alt="Jax/Flax × TransformersでBERTのfine-tuningをTPUで行う | 株式会社AI Shift" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/011/970/025/thumb/44c23b6b15d70994d766716b66bcaf1c.png?1635230157" />
<strong style='display: block;'><a href="https://www.ai-shift.co.jp/techblog/2209?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Jax/Flax × TransformersでBERTのfine-tuningをTPUで行う | 株式会社AI Shift</a> &mdash; <a href="https://www.ai-shift.co.jp/techblog/2209">www.ai-shift.co.jp</a></strong>
AI ShiftのTECH BLOGです。AI技術の情報や活用方法などをご案内いたします。
</p>
<div style='clear: both;'></div>
<p><p>Googleの深層学習ライブラリ「<a href="https://github.com/google/flax" target="_blank">Flax</a>」を用いて、TPUでBERTのファインチューニングをする方法を解説している記事。Kaggle「<a href="https://www.kaggle.com/c/commonlitreadabilityprize" target="_blank">CommonLit Readability Prize</a>」を題材にしています。</p></p>
<p>
<img width="140" height="140" alt="Google AI Blog: Deciding Which Tasks Should Train Together in Multi-Task Neural Networks" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/011/970/044/thumb/GoogleAI_logo_horizontal_color_rgb.png?1635230321" />
<strong style='display: block;'><a href="https://ai.googleblog.com/2021/10/deciding-which-tasks-should-train.html?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Google AI Blog: Deciding Which Tasks Should Train Together in Multi-Task Neural Networks</a> &mdash; <a href="https://ai.googleblog.com/2021/10/deciding-which-tasks-should-train.html">ai.googleblog.com</a></strong>
<p>Many machine learning (ML) models typically focus on learning one task at a time.</p>
</p>
<div style='clear: both;'></div>
<p><p>国際学会「NeurIPS 2021」採択の「<a href="https://arxiv.org/abs/2109.04617" target="_blank">Efficiently Identifying Task Groupings for Multi-Task Learning</a>」の解説記事。ニューラルネットワークで複数のタスクを同時に解く「マルチタスク学習」をする価値のあるタスクを選ぶ方法を提案しています。</p></p>
<p>
<img width="140" height="140" alt="エンジニアはデータサイエンスコンペティションを活用するべき理由 -Atraeとbitgritが共催したAIコンペ「#SwipeToSuccess」のすべて-｜DataGateway株式会社｜note" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/011/992/981/thumb/rectangle_large_type_2_735644b03de2f12c73d6656a46431431.jpg?1635333796" />
<strong style='display: block;'><a href="https://note.com/datagateway/n/n19d015dd7483?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">エンジニアはデータサイエンスコンペティションを活用するべき理由 -Atraeとbitgritが共催したAIコンペ「#SwipeToSuccess」のすべて-｜DataGateway株式会社｜note</a> &mdash; <a href="https://note.com/datagateway/n/n19d015dd7483">note.com</a></strong>
<p>昨年AIコンペティション「#SwipeToSuccess」（以下「コンペ」という）を共催しました。</p>
</p>
<div style='clear: both;'></div>
<p><p>ビジネス版マッチングアプリ「<a href="https://page.yenta-app.com/jp" target="_blank">Yenta</a>」のデータセットを用いて昨年開催した「<a href="https://bitgrit.net/competition/4" target="_blank">#SwipeToSuccess</a>」コンペを振り返った記事。コンペ概要や、Kaggle Grandmasterの<a href="https://www.kaggle.com/senkin13" target="_blank">Senkinさん</a>のコメントなどが掲載されています。</p></p>
<p>
<strong style='display: block;'><a href="https://press.aboutamazon.com/news-releases/news-release-details/aws-announces-general-availability-amazon-ec2-dl1-instances?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">AWS Announces General Availability of Amazon EC2 DL1 Instances | Amazon.com, Inc. - Press Room</a></strong>
<p>New Amazon EC2 instances featuring Gaudi accelerators from Habana Labs deliver up to 40% better price performance for training machine learning models compared to the latest GPU-based Amazon EC2 instances.</p>
</p>
<p><p>AWSは26日、機械学習モデルの学習に特化した「Amazon EC2 DL1インスタンス」を一般利用可能にしました。汎用GPUと比較して価格効率が40%優れている点などが記載されています。</p></p>
<p>
<strong style='display: block;'><a href="https://www.kaggle.com/iamleonie/trying-this-in-japanese-en-sub?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">日本語でやってみたかった。Trying this in Japanese. [en sub] | Kaggle</a></strong>
Explore and run machine learning code with Kaggle Notebooks | Using data from 2021 Kaggle Machine Learning &amp; Data Science Survey
</p>
<p><p>Kaggleが実施した大規模アンケートの回答を用いて、日本の特徴について分析しているNotebook。女性比率の低さや平均年齢の高さなどが可視化されています。</p></p>
