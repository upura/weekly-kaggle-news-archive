# Weekly Kaggle News #29
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-29-259401
<h3><h2>News &amp; Competitions</h2><p>多くのコンペが終了した週でした。日本からの参加者の入賞も多く、twitterでは結果に一喜一憂する投稿が目立ちました。</p><p>Kaggle「<a href="https://www.kaggle.com/c/trends-assessment-prediction" target="_blank">TReNDS Neuroimaging</a>」コンペは29日に終わりました。上位陣は<a href="https://mlwave.com/kaggle-ensembling-guide/" target="_blank">stacking</a>を活用しており、テーブルデータだけではなく画像データからも特徴を抽出していました。脳のMRI画像から抽出した特徴を用いて、年齢などを推定するタスクでした。金メダル圏内には日本からの参加者が目立ち、<a href="https://www.rist.co.jp/202006302590/" target="_blank">企業リリース</a>も出ています。4日には<a href="https://twitter.com/tkm2261/status/1277849334852149249?s=20" target="_blank">参加者有志ら</a>による<a href="https://youtu.be/QDcMR9h2e2M" target="_blank">YouTube配信</a>が予定されています。</p><p>Kaggleでは「<a href="https://www.kaggle.com/c/m5-forecasting-accuracy" target="_blank">M5 Forecasting&nbsp;- Accuracy</a>」「<a href="https://www.kaggle.com/c/m5-forecasting-uncertainty" target="_blank">M5 Forecasting - Uncertainty</a>」コンペも30日に終了しました。Walmartが提供する商品購買データを使った時系列予測コンペで、最終順位のために選ぶ提出が1つのみだった仕様もあり、波乱含みの結果となりました。<a href="https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/163410" target="_blank">Accuracyの上位300チームの国別の分布</a>では、日本が最も多かったそうです。</p><p>SIGNATE「<a href="https://signate.jp/competitions/256" target="_blank">第3回AIエッジコンテスト（アルゴリズムコンテスト②）</a>」コンペは30日に終わりました。<a href="https://signate.jp/competitions/256/discussions" target="_blank">フォーラム</a>に解法が投稿されている点が、SIGNATEとしては珍しいです。翌1日には「<a href="https://signate.jp/competitions/285" target="_blank">第4回AIエッジコンテスト（実装コンテスト②）</a>」コンペが始まりました。</p><p>ProbSpace「<a href="https://prob.space/competitions/youtube-view-count" target="_blank">YouTube動画視聴回数予測</a>」コンペは28日に終了しました。テーブル・画像・テキストと多様なデータが利用できるコンペで、<a href="https://twitter.com/senkin13/status/1277443764206727169?s=20" target="_blank">1位</a>ら上位陣の解法は<a href="https://prob.space/competitions/youtube-view-count/discussions" target="_blank">トピック</a>で共有されています。</p><p>Kaggleでは「<a href="https://www.kaggle.com/c/landmark-retrieval-2020" target="_blank">Google Landmark Retrieval 2020</a>」コンペが30日に始まりました。今年は<a href="https://www.kaggle.com/c/landmark-retrieval-2020/overview/code-requirements" target="_blank">実行コードも提出する形式</a>で、<a href="https://www.kaggle.com/c/landmark-retrieval-2020/discussion/163086" target="_blank">TensorFlow 2.2の指定</a>がある点も特徴的です。</p><p>Kaggle運営のWalterさんは1日、テーブルデータを扱うコンペ開催の準備を進めていると<a href="https://mobile.twitter.com/WalterReade/status/1278355395338256384" target="_blank">明らかにしました</a>。</p><p>「Minecraft」が題材の強化学習コンペ「<a href="https://minerl.io/competition/" target="_blank">MineRL Competition 2020</a>」が2日に始まりました。国際学会「NeurIPS」の中で開催されるコンペで、運営には日本からPreferred Networksも関わっています。概要は昨年の開催時の勉強会発表「<a href="https://youtu.be/xTI_slfDKe8" target="_blank">目指せ NeurIPS 2019 : MineRL Competition</a>」が分かりやすいです。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="Addison Howard, Maggie Demkin, Phil Culliton | Kaggle Team | CTDS.Show #79" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/201/599/thumb/maxresdefault.jpg?1593747533" />
<strong style='display: block;'><a href="https://www.youtube.com/watch?feature=youtu.be&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter&amp;v=-eU2z8xWpEs">Addison Howard, Maggie Demkin, Phil Culliton | Kaggle Team | CTDS.Show #79</a> &mdash; <a href="https://www.youtube.com/watch?v=-eU2z8xWpEs&amp;feature=youtu.be">www.youtube.com</a></strong>
Audio (Podcast Version) available here: https://anchor.fm/chaitimedatascience Subscribe here to the newsletter: https://tinyletter.com/sanyambhutani In this ...
</p>
<div style='clear: both;'></div>
<p><p><a href="https://www.youtube.com/channel/UCRjtBP-o5FbgRzX2BHQEFtQ?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">YouTube</a>などでKagglerへのインタビュー「<a href="https://chaitimedatascience.com/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">Chai Time Data Science Show</a>」を公開している<a href="https://www.kaggle.com/init27?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">Sanyam Bhutani</a>さんの最新作。Kaggleの「中の人」3名に話を聞いています。</p></p>
<p>
<strong style='display: block;'><a href="https://www.kaggle.com/c/global-wheat-detection/discussion/161296?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Global Wheat Detection | Kaggle</a></strong>
Can you help identify wheat heads using image analysis?
</p>
<p><p>Kaggleで開催中の「<a href="https://www.kaggle.com/c/global-wheat-detection" target="_blank">Global Wheat Detection</a>」コンペでの不正を訴える投稿。チームメイトが解法を勝手に販売する事案が報告されています。</p></p>
<p>
<strong style='display: block;'><a href="https://www.kaggle.com/community-guidelines?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Kaggle Community Guidelines</a></strong>
Ensuring Kaggle is a place where anyone in the world feels welcome to participate
</p>
<p><p>Kaggleは更新したコミュニティ・ガイドラインを2日に<a href="https://twitter.com/kaggle/status/1278428173814857728?s=20" target="_blank">共有</a>しました。行動規範や報告の方法などが掲載されています。</p></p>
<p>
<strong style='display: block;'><a href="https://jp.ricoh.com/info/2020/0626_1?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">リコーの研究者がAIの世界的なデータ分析コンペ「Kaggle」で Gold メダルを受賞 | リコーグループ 企業・IR | リコー</a></strong>
【リコー公式サイト】株式会社リコーの研究者であるイノベーション本部 光システム応用研究センター センシングAI研究室の平口 裕紀が、AI（人工知能）を用いたデータ分析技術の国際的なコンペティションプラットフォーム「Kaggle（カグル）」上の「Abstraction and Reasoning Challenge（抽象化と推論への挑戦）」で Gold メダルを受賞しました。
</p>
<p><p>Kaggle「<a href="https://www.kaggle.com/c/abstraction-and-reasoning-challenge" target="_blank">Abstraction and Reasoning Challenge</a>」コンペでの金メダル獲得を伝える内容。日本の企業がKaggleでの成果をリリースする事例が増えている印象です。</p></p>
<p>
<img width="140" height="140" alt="dplyr 1.0.0の新機能 / dplyr 1.0.0 - Speaker Deck" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/176/665/thumb/slide_0.jpg?1593264837" />
<strong style='display: block;'><a href="https://speakerdeck.com/y__mattu/dplyr-1-dot-0-0?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">dplyr 1.0.0の新機能 / dplyr 1.0.0 - Speaker Deck</a> &mdash; <a href="https://speakerdeck.com/y__mattu/dplyr-1-dot-0-0">speakerdeck.com</a></strong>

</p>
<div style='clear: both;'></div>
<p><p>R言語でテーブルデータを扱う「dplyr」ライブラリのv1.0.0の新機能を紹介しているスライド。既存からの変更点や追加された関数などをまとめています。</p></p>
<p>
<img width="140" height="140" alt="Getting Started with AutoKeras - Towards Data Science" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/177/551/thumb/1*_9fgb9BS5GNdFeS0A7LR6w.jpeg?1593287486" />
<strong style='display: block;'><a href="https://towardsdatascience.com/getting-started-with-autokeras-8c5332b829?gi=b075ccdf13c8&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Getting Started with AutoKeras - Towards Data Science</a> &mdash; <a href="https://towardsdatascience.com/getting-started-with-autokeras-8c5332b829?gi=b075ccdf13c8">towardsdatascience.com</a></strong>
One of the most powerful upcoming concepts which I wrote about in The State of AI in 2020 is Neural Architecture Search(NAS). There is plenty to know about NAS, but to understand this tutorial I will…
</p>
<div style='clear: both;'></div>
<p><p>ニューラルネットワークの構造を自動探索する「<a href="https://dl.acm.org/doi/10.1145/3292500.3330648" target="_blank">AutoKeras</a>」の紹介。テーブル・画像・テキストの分類・回帰などのタスクに対応しています。</p></p>
<p>
<strong style='display: block;'><a href="https://harish3110.github.io/through-tinted-lenses/natural%20language%20processing/sentiment%20analysis/2020/06/27/Introduction-to-NLP-using-Fastai.html?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Introduction to NLP using Fastai | Through Tinted Lenses</a></strong>
Implementing and decoding the revolutionary ULMFiT approach to train a language model on any downstream NLP task.
</p>
<p><p>Kaggle「<a href="https://www.kaggle.com/c/nlp-getting-started" target="_blank">Real or Not? NLP with Disaster Tweets</a>」コンペを題材に「Fastai」ライブラリを用いて自然言語処理モデルを利用するチュートリアル。データの可視化から予測までの一連の流れをまとめています。</p></p>
<p>
<img width="140" height="140" alt="Viewing text through the eyes of a machine - Towards Data Science" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/179/416/thumb/1*hKeqIQawev6-vyDN8KmGyw.png?1593356393" />
<strong style='display: block;'><a href="https://towardsdatascience.com/viewing-text-through-the-eyes-of-a-machine-db30c744ee17?gi=c98845badcb6&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Viewing text through the eyes of a machine - Towards Data Science</a> &mdash; <a href="https://towardsdatascience.com/viewing-text-through-the-eyes-of-a-machine-db30c744ee17?gi=c98845badcb6">towardsdatascience.com</a></strong>
We have been able to lift the lid on Convolutional Neural Networks (CNN) in computer vision tasks for a number of years now. This has brought with it significant improvements to the field through…
</p>
<div style='clear: both;'></div>
<p><p>文書の2値分類タスクにおけるKerasのCNNの特徴を可視化する方法のチュートリアル。予測結果の分析に使えそうです。</p></p>
<p>
<img width="140" height="140" alt="実践Deep Learning：波形データのシーケンスラベリングと信号処理" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/179/899/thumb/maxresdefault.jpg?1593365555" />
<strong style='display: block;'><a href="https://www.youtube.com/watch?feature=youtu.be&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter&amp;v=_4r7uTIPG1s">実践Deep Learning：波形データのシーケンスラベリングと信号処理</a> &mdash; <a href="https://www.youtube.com/watch?v=_4r7uTIPG1s&amp;feature=youtu.be">www.youtube.com</a></strong>
Deep Learningを用いて波形の時刻ごとの分類を行うシーケンスラベリングや、信号処理に用いることのできる基本的なアーキテクチャをご紹介します。 前回の動画：Deep Learningによる波形データの分類と回帰 https://www.youtube.com/watch?v=22Eq_0qADf4 実践D...
</p>
<div style='clear: both;'></div>
<p><p>波形データを扱うニューラルネットワークのアーキテクチャについての解説動画。<a href="https://www.youtube.com/channel/UCRTV5p4JsXV3YTdYpTJECRA" target="_blank">SONYの小林さんによる動画シリーズ</a>は、深層学習に関するトピックが分かりやすく取り上げられています。SONYが開発しOSSとして公開しているニューラルネットワークライブラリ「Neural Network Libraries」は1日に<a href="https://blog.nnabla.org/ja/release/v1-9-0/" target="_blank">v1.9.0</a>が公開され、日本語版ドキュメントが追加されました。</p></p>
<p>
<img width="140" height="140" alt="Release New tokenizer API, TensorFlow improvements, enhanced documentation &amp; tutorials · huggingface/transformers · GitHub" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/195/838/thumb/a16c4880-a501-11ea-9e8f-646cf611702e?1593635344" />
<strong style='display: block;'><a href="https://github.com/huggingface/transformers/releases/tag/v3.0.0?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Release New tokenizer API, TensorFlow improvements, enhanced documentation &amp; tutorials · huggingface/transformers · GitHub</a> &mdash; <a href="https://github.com/huggingface/transformers/releases/tag/v3.0.0">github.com</a></strong>
🤗Transformers: State-of-the-art Natural Language Processing for Pytorch and TensorFlow 2.0. - huggingface/transformers
</p>
<div style='clear: both;'></div>
<p><p>最先端の自然言語処理モデルを扱える「Transformers」ライブラリのv3がリリース。ドキュメントやチュートリアルの刷新、新しいトークナイズAPIなどの<a href="https://mobile.twitter.com/huggingface/status/1277977122212986881" target="_blank">更新</a>があります。</p></p>
<p>
<img width="140" height="140" alt="Approaching (Almost) Any Machine Learning Problem: 9788269211504: Computer Science Books @ Amazon.com" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/195/983/thumb/AFR_Evergreen_HeroQuickPromo350X70._CB485917500_.jpg?1593637595" />
<strong style='display: block;'><a href="https://www.amazon.com/dp/8269211508?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Approaching (Almost) Any Machine Learning Problem: 9788269211504: Computer Science Books @ Amazon.com</a> &mdash; <a href="https://www.amazon.com/dp/8269211508">www.amazon.com</a></strong>
Approaching (Almost) Any Machine Learning Problem: 9788269211504: Computer Science Books @ Amazon.com
</p>
<div style='clear: both;'></div>
<p><p>Kaggleの全4カテゴリでGrandmasterの称号を持つ<a href="https://www.kaggle.com/abhishek" target="_blank">Abhishek</a>さんが自主出版した書籍が発売されました。<a href="https://twitter.com/abhi1thakur/status/1278297387094728704?s=20" target="_blank">各国向けの購入リンク</a>も用意されており、<a href="https://www.amazon.co.jp/dp/8269211508" target="_blank">日本のAmazon</a>からも購入可能です。</p></p>
<p>
<img width="140" height="140" alt="型ヒントでPython開発を加速 ～Microsoft、VS Code向けの拡張機能「Pylance」を発表／“IntelliSense”による強力な入力補完や型チェック、モジュールの自動インポートが利用可能に" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/197/661/thumb/image1.jpg?1593683062" />
<strong style='display: block;'><a href="https://forest.watch.impress.co.jp/docs/news/1262974.html?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">型ヒントでPython開発を加速 ～Microsoft、VS Code向けの拡張機能「Pylance」を発表／“IntelliSense”による強力な入力補完や型チェック、モジュールの自動インポートが利用可能に</a> &mdash; <a href="https://forest.watch.impress.co.jp/docs/news/1262974.html">forest.watch.impress.co.jp</a></strong>

</p>
<div style='clear: both;'></div>
<p><p>米Microsoftが30日に「Visual Studio Code」向けの拡張機能「Pylance」を発表。同社の開発する静的型チェックツール「Pyright」による型ヒントなどが利用可能です。早速<a href="https://qiita.com/simonritchie/items/33ca57cdb5cb2a12ae16" target="_blank">「使ってみた」記事</a>も公開されています。</p></p>
<p>
<img width="140" height="140" alt="DeNA, MoT合同輪講発表資料「Domain Adaptation 入門」 - Speaker Deck" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/201/519/thumb/slide_0.jpg?1593746185" />
<strong style='display: block;'><a href="https://speakerdeck.com/takarasawa_/dena-mothe-tong-lun-jiang-fa-biao-zi-liao-domain-adaptation-ru-men?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">DeNA, MoT合同輪講発表資料「Domain Adaptation 入門」 - Speaker Deck</a> &mdash; <a href="https://speakerdeck.com/takarasawa_/dena-mothe-tong-lun-jiang-fa-biao-zi-liao-domain-adaptation-ru-men">speakerdeck.com</a></strong>

</p>
<div style='clear: both;'></div>
<p><p>転移学習の一つとして位置づけられる「Domain Adaptation」についての解説資料。タスクの概要や手法の分類などをまとめています。</p></p>
<p>
<img width="140" height="140" alt="Google Colab Tips for Power Users - Amit Chaudhary" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/201/546/thumb/colab-cover.png?1593746408" />
<strong style='display: block;'><a href="https://amitness.com/2020/06/google-colaboratory-tips/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Google Colab Tips for Power Users - Amit Chaudhary</a> &mdash; <a href="https://amitness.com/2020/06/google-colaboratory-tips/">amitness.com</a></strong>
Learn about lesser-known features in Google Colaboratory to improve your productivity.
</p>
<div style='clear: both;'></div>
<p><p>ブラウザ上のコード実行環境「&nbsp;Google Colaboratory」の便利なTipsを紹介している記事。TensorFlowのバージョン切り替えやPandasのDataFrameのインタラクティブ表示など、あまり知られていない機能をまとめています。</p></p>
