# Weekly Kaggle News #4
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-4-218884
<h3><h2>News</h2><p>強化学習を題材にしたKaggle「<a href="https://www.kaggle.com/c/connectx" target="_blank">Connect X</a>」コンペが4日に始まりました。「Simulations Competitions」と呼ばれる新形式で、提出したモデルを戦わせながらLeaderboardが変動していきます。昨年12月開催の「<a href="https://kaggledays.com/tokyo/" target="_blank">Kaggle Days Tokyo</a>」にて、KaggleのCTOを務める<a href="https://www.kaggle.com/benhamner" target="_blank">Ben Hamnerさん</a>が予告していました。同コンペは「β版」のためメダルは付与されませんが、機械学習の教師あり学習の枠組みが主流となっているKaggleの中で、動向に注目が集まります。</p><h2>Competitions</h2><p>アメフトのプレイデータを用いたKaggle「<a href="https://www.kaggle.com/c/nfl-big-data-bowl-2020" target="_blank">NFL Big Data Bowl</a>」コンペの最終結果が7日に発表されました。1位チームは特徴量エンジニアリングをほぼ行わず、2次元CNNを用いて選手間の位置関係などの特徴表現を獲得していました。取り組みは<a href="https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/119400" target="_blank">discussion</a>に投稿されており、<a href="https://takuoko.hatenablog.com/entry/2019/12/13/012721" target="_blank">再現を試みた日本語のブログ</a>も公開されています。独自性のある解法で、PublicでもPrivateでも2位以下から頭一つ抜けたスコアを出しての優勝でした。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="tomomoto on Twitter: &quot;PandasのIndexクラスの基礎をnoteでまとめ中。 正月で全部書ききるつもりが、別件で全然時間とれなかったので書いている部分だけでも公開。（note使ってみたい気持ちでかいたので、今後書ききるかは気分次第。） https://t.co/WLurQ8m9e6&quot;" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/390/674/thumb/oTcPYsT8_400x400.png?1578156827" />
<strong style='display: block;'><a href="https://twitter.com/tomomoto_LV3/status/1213325356582592512?s=20&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">tomomoto on Twitter: &quot;PandasのIndexクラスの基礎をnoteでまとめ中。 正月で全部書ききるつもりが、別件で全然時間とれなかったので書いている部分だけでも公開。（note使ってみたい気持ちでかいたので、今後書ききるかは気分次第。） https://t.co/WLurQ8m9e6&quot;</a> &mdash; <a href="https://twitter.com/tomomoto_LV3/status/1213325356582592512?s=20">twitter.com</a></strong>

</p>
<div style='clear: both;'></div>
<p><p>『<a href="https://gihyo.jp/book/2018/978-4-7741-9647-3" target="_blank">前処理大全</a>』の著者であるtomomotoさんによる「PandasのIndexクラスの基礎」まとめ。Pythonでテーブルデータコンペ上で必要不可欠なPandasについて、Indexクラスを軸に解説しています。</p></p>
<p>
<img width="140" height="140" alt="自然言語処理におけるEmbeddingの方法一覧とサンプルコード - 機械学習 Memo φ(・ω・ )" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/387/720/thumb/20200103102212.png?1578053337" />
<strong style='display: block;'><a href="https://yukoishizaki.hatenablog.com/entry/2020/01/03/175156?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">自然言語処理におけるEmbeddingの方法一覧とサンプルコード - 機械学習 Memo φ(・ω・ )</a> &mdash; <a href="https://yukoishizaki.hatenablog.com/entry/2020/01/03/175156">yukoishizaki.hatenablog.com</a></strong>
概要 自然言語処理における単語や文章のEmbeddingの方法を勉強したので概要を記載しました。 また、学習済みモデルからEmbeddingベクトルを取得するサンプルソースコードも一部記載しました。 概要 Word2vec fastText GloVe Skip-thought SCDV USE ELMo BERT おわり 宣伝 Word2vec 似た意味の単語の周りには同じような単語が出現するとして、ある単語の周辺に出現する単語を予測するNNの隠れ層の重みを、ある単語のベクトルとしたもの。Doc2vecはWord2vecを文章に拡張したもの。NNには以下のようなSkip-Gramのモデルが使…
</p>
<div style='clear: both;'></div>
<p><p>自然言語処理における単語や文章のEmbedding方法を解説。Universal Sentence EncoderやBERTなど、最近の手法も扱っています。学習済みモデルからベクトルを取得するサンプルソースコードも記載されています。</p></p>
<p>
<img width="140" height="140" alt="BERT入門" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/409/075/thumb/20200109introductionofbert-200109092742-thumbnail-4.jpg?1578589959" />
<strong style='display: block;'><a href="https://www.slideshare.net/matsukenbook/bert-217710964?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">BERT入門</a> &mdash; <a href="https://www.slideshare.net/matsukenbook/bert-217710964">www.slideshare.net</a></strong>
2020年1月の社内勉強会でBERTについて紹介した時のスライドです。
</p>
<div style='clear: both;'></div>
<p><p>BERTの特徴、Pre-trainingの方法、transformersライブラリの実装を基にしたモデル構造の可視化などを紹介。図解が丁寧で簡潔にまとまっています。</p></p>
<p>
<strong style='display: block;'><a href="https://www.kaggle.com/bibek777/bert-baseline?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">BERT Baseline | Kaggle</a></strong>
Using data from multiple data sources
</p>
<p><p>NLPを題材にしたKaggleのチュートリアルコンペ「<a href="https://www.kaggle.com/c/nlp-getting-started" target="_blank">Real or Not? NLP with Disaster Tweets</a>」で公開されたNotebook。PyTorchのtransformersライブラリを用いたBERTのFine tuningから予測までの一連の流れがまとまっています。</p></p>
<p>
<img width="140" height="140" alt="The path to my current job in the Autonomous Industry" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/406/353/thumb/1*_mUt257egvgT7zOL_YR2aQ.png?1578552613" />
<strong style='display: block;'><a href="https://towardsdatascience.com/how-i-found-my-current-job-3fb22e511a1f?gi=e7a0e1df0fcc&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">The path to my current job in the Autonomous Industry</a> &mdash; <a href="https://towardsdatascience.com/how-i-found-my-current-job-3fb22e511a1f?gi=e7a0e1df0fcc">towardsdatascience.com</a></strong>
The new year is a time for stories. Let me tell you one on how I found a job in deep learning (DL) / computer vision (CV). In January of 2017, I was working in a company called TrueAccord, located…
</p>
<div style='clear: both;'></div>
<p><p>Kaggle Grandmasterの<a href="https://www.kaggle.com/iglovikov" target="_blank">Vladimir Iglovikovさん</a>がdeep learning / computer vision業界へ飛び込むまでの体験記。一筋縄ではいかない挫折も含め、Kaggleと共に歩んだ経験が生々しく語られています。</p></p>
