# Weekly Kaggle News #15
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-15-234643
<h3><h2>News</h2><p>今週は、Kaggleで2つのNLPコンペが始まりました。「<a href="https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification" target="_blank">Jigsaw Multilingual Toxic Comment Classification</a>」コンペのタスクは、多言語の悪質なコメント検知です。TPUの使用が推奨されています。「<a href="https://www.kaggle.com/c/tweet-sentiment-extraction" target="_blank">Tweet Sentiment Extraction</a>」は、英語の文章の中から感情を表す部分を抽出するコンペです。</p><h2>Competitions</h2><p>音声の異常検知を題材とした「<a href="http://dcase.community/challenge2020/task-unsupervised-detection-of-anomalous-sounds" target="_blank">DCASE 2020 Task 2 Unsupervised Detection of Anomalous Sounds for Machine Condition Monitoring</a>」コンペが開催中です。コンペ概要やベンチマークとなるコードなどをまとめた<a href="https://qiita.com/daisukelab/items/b106c567cf8927a5519a" target="_blank">日本語記事</a>が公開されています。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="「見るべきは称号だけじゃない。そこに至る学びや実力が重要」Kaggle本著者が語るKaggleへの取り組み方 | TRaiNZ" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/722/231/thumb/DSC09159-790x540.jpg?1585138797" />
<strong style='display: block;'><a href="https://trainz.jp/media/89/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">「見るべきは称号だけじゃない。そこに至る学びや実力が重要」Kaggle本著者が語るKaggleへの取り組み方 | TRaiNZ</a> &mdash; <a href="https://trainz.jp/media/89/">trainz.jp</a></strong>
『Kaggle データ分析の技術』を出版された門脇大輔さんにKaggleについてインタビューしました。
</p>
<div style='clear: both;'></div>
<p><p>『Kaggleで勝つデータ分析の技術』の著者の一人である<a href="https://www.kaggle.com/threecourse" target="_blank">門脇さん（threecourse）</a>へのインタビュー記事。執筆の背景や反響などについて語られています。</p></p>
<p>
<img width="140" height="140" alt="&quot;Inversion&quot;: Walter Reade | Data Science at Kaggle | Becoming a Data Scientist &amp; Kaggle Grandmaster" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/710/215/thumb/maxresdefault.jpg?1584935446" />
<strong style='display: block;'><a href="https://www.youtube.com/watch?feature=youtu.be&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter&amp;v=OoB_LQpgDCk">&quot;Inversion&quot;: Walter Reade | Data Science at Kaggle | Becoming a Data Scientist &amp; Kaggle Grandmaster</a> &mdash; <a href="https://www.youtube.com/watch?v=OoB_LQpgDCk&amp;feature=youtu.be">www.youtube.com</a></strong>
Enjoy the videos and music you love, upload original content, and share it all with friends, family, and the world on YouTube.
</p>
<div style='clear: both;'></div>
<p><p>Kaggle運営の<a href="https://www.kaggle.com/inversion" target="_blank">Walterさん（Inversion）</a>へのインタビュー動画。Kaggleに入社する前の話も含めて「中の人」への貴重な質疑となっています。</p></p>
<p>
<img width="140" height="140" alt="深層学習モデルの実装を爆速にするVSCodeの設定メモ - May the Neural Networks be with you" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/715/445/thumb/41br_6nMreL._SL160_.jpg?1585012787" />
<strong style='display: block;'><a href="http://shunk031.hatenablog.com/entry/how-to-setup-vscode-for-developing-deep-learning-model?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">深層学習モデルの実装を爆速にするVSCodeの設定メモ - May the Neural Networks be with you</a> &mdash; <a href="http://shunk031.hatenablog.com/entry/how-to-setup-vscode-for-developing-deep-learning-model">shunk031.hatenablog.com</a></strong>
こんにちは。@shunk031です。 新型コロナウイルスが猛威を奮っていますね。 不要不急の外出は控えるのが大切そうです。 こういう時は引きこもって論文を読むのが一番です。 今回はコードエディタであるVSCodeで、深層学習モデルの実装を爆速にするための設定についてメモします。 深層学習モデルの実装をする際にはリモート上にあるGPUを搭載したサーバで実装をしたりデバッグすることが非常に多いです。 VSCodeはこうしたリモートでのコード編集およびデバッグを簡単に行える仕組みを多数揃えています。 本記事では、深層学習モデルの実装に頻繁に利用されるPythonを対象に、以下の観点からモデルの実装を…
</p>
<div style='clear: both;'></div>
<p><p>エディタ「VSCode」を用いて深層学習モデルの実装を進める上での諸設定を解説。Pythonの開発環境・リモート接続・デバッグなどの観点でまとめられています。</p></p>
<p>
<img width="140" height="140" alt="Confident Learning -そのラベルは正しいか？- - 学習する天然ニューラルネット" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/731/891/thumb/20200326213339.jpg?1585273117" />
<strong style='display: block;'><a href="https://aotamasaki.hatenablog.com/entry/confident_learning?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Confident Learning -そのラベルは正しいか？- - 学習する天然ニューラルネット</a> &mdash; <a href="https://aotamasaki.hatenablog.com/entry/confident_learning">aotamasaki.hatenablog.com</a></strong>
これは何？ ICML2020に投稿された Confident Learning: Estimating Uncertainty in Dataset Labels という論文が非常に面白かったので、その論文まとめを公開する。 論文 [1911.00068] Confident Learning: Estimating Uncertainty in Dataset Labels 超概要 データセットにラベルが間違ったものがある(noisy label)。そういうサンプルを検出したい Confident Learningという方法を提案。現実的な状況下でSOTAを達成 PyPIに実装を公開済みです…
</p>
<div style='clear: both;'></div>
<p><p>ICML2020「Confident Learning: Estimating Uncertainty in Dataset Labels」の解説。データセット内の間違ったラベルを検知する仕組みを提案。汎用性が高そうな枠組みになっています。pip installも可能です。</p></p>
<p>
<img width="140" height="140" alt="PyTorchで高精度・高性能のEfficientNetを利用する - のんびりしているエンジニアの日記" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/005/731/951/thumb/1585179357?1585274655" />
<strong style='display: block;'><a href="https://nonbiri-tereka.hatenablog.com/entry/2020/03/26/083557?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">PyTorchで高精度・高性能のEfficientNetを利用する - のんびりしているエンジニアの日記</a> &mdash; <a href="https://nonbiri-tereka.hatenablog.com/entry/2020/03/26/083557">nonbiri-tereka.hatenablog.com</a></strong>
皆さんこんにちは お元気でしょうか。本日はEfficientNetをPyTorchで利用します。 私も頻繁に利用しますが、時々忘れてしまうのでメモ EfficnetNetについて EfficientNetとは？ 幅、深さや解像度に関係性を導き出されたニューラルネットワークのアーキテクチャ。 SoTAを出したが、従来より8.4倍小さく、6.1倍の高速化を実現しています。 EfficientB0-B7（今はそれ以上もあった気もしますが）まで存在し、精度・性能により使い分けできます。 Kagglerたちは最近このニューラルネットワークをソリューションに利用するようになりました。（ResNetより増え…
</p>
<div style='clear: both;'></div>
<p><p>EfficientNetをPyTorchで使う方法を解説。近年のKaggleの画像コンペで頻繁に利用されている印象です。</p></p>
<p>
<strong style='display: block;'><a href="https://arxiv.org/abs/2002.10107?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">[2002.10107] Predicting Subjective Features from Questions on QA Websites using BERT</a></strong>

</p>
<p><p>Kaggle「Google QUEST Q&amp;A Labeling」コンペのデータを利用した論文。<a href="https://github.com/Moradnejad/Predicting-Subjective-Features-on-QA-Websites" target="_blank">GitHub</a>でソースコードも公開しています。</p><p><br></p></p>
