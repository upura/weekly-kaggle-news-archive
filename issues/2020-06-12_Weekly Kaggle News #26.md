# Weekly Kaggle News #26
https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-26-254332
<h3><h2>News</h2><p>「<a href="https://www.ai-gakkai.or.jp/jsai2020/" target="_blank">人工知能学会全国大会</a>」「<a href="https://confit.atlas.jp/guide/event/ssii2020/top" target="_blank">画像センシングシンポジウム</a>」「<a href="https://cloudonair.withgoogle.com/events/google-cloud-day-digital" target="_blank">Google Cloud Day: Digital</a>」など、大規模なオンラインイベントが開催された週でした。人工知能学会では、日本のコンペティションプラットフォームを運営する<a href="https://signate.jp/" target="_blank">SIGNATE</a>と<a href="https://www.nishika.com/" target="_blank">Nishika</a>が企業セッションで発表しました。Google Cloud Day: Digitalでは『<a href="https://www.amazon.co.jp/dp/4297108437" target="_blank">Kaggleで勝つデータ分析の技術</a>』の著者らが「Kaggle で勝つ GCP の活用方法」の題目で<a href="https://cloudonair.withgoogle.com/events/google-cloud-day-digital?talk=d3-ml07" target="_blank">講演しました</a>。</p><p>PyTorchで学習したモデルのデプロイを簡略化するTorchServeの<a href="https://github.com/pytorch/serve/releases/tag/v0.1.1" target="_blank">v0.1.1</a>が10日にリリースされました。NLPの最先端の言語モデルを提供するHuggingFaceの<a href="https://github.com/huggingface/transformers" target="_blank">Transformers</a>がサポートされ、<a href="https://github.com/pytorch/serve/tree/master/examples/Huggingface_Transformers" target="_blank">examples</a>が追加されました。</p><h2>Competitions</h2><p>20人以上のKaggle Masterを含む約200チームが参加した「<a href="https://atma.connpass.com/event/175139/?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">atmaCup オンサイトデータコンペ#5</a>」が6日に終了しました。データの具体的な中身以外は公開が許可されており、多くの方がブログやGitHubなどで解法を共有しています（<a href="https://togetter.com/li/1539991" target="_blank">ツイートまとめ</a>）。</p><p><a href="https://www.youtube.com/channel/UCRjtBP-o5FbgRzX2BHQEFtQ" target="_blank">YouTube</a>などでKagglerへのインタビュー「<a href="https://chaitimedatascience.com/" target="_blank">Chai Time Data Science Show</a>」を公開している<a href="https://www.kaggle.com/init27" target="_blank">Sanyam Bhutaniさん</a>は、インタビューの音声・記事データを用いた分析コンペを21日から開催します。評価項目は可視化・気付き・ストーリーなどで、KaggleのNotebookランク1位の<a href="https://www.kaggle.com/artgor" target="_blank">Andrew Lukyanenkoさん</a>ら4人のNotebook Grandmasterが審査員を務めます。</p></h3>
<hr>
<p>
<img width="140" height="140" alt="機械学習の勉強を始めて1年以内にkaggleで2位になったので、やったこと全部書く - 趣味日記" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/073/056/thumb/20200605123738.png?1591335192" />
<strong style='display: block;'><a href="https://aryyyyy.hatenablog.com/entry/2020/06/05/122356?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">機械学習の勉強を始めて1年以内にkaggleで2位になったので、やったこと全部書く - 趣味日記</a> &mdash; <a href="https://aryyyyy.hatenablog.com/entry/2020/06/05/122356">aryyyyy.hatenablog.com</a></strong>
初めまして、aryyyyyと申します。 先日kaggleのARCコンペで2位になったのですが、 2位で終了しました！みなさんお疲れさまでした。コード書くの楽しかった。 pic.twitter.com/dLxl6Mlgoe — Aryyyyy (@aryyyyy13) 2020年5月28日 僕のkaggle歴が浅めということもありtwitterでも結構反響があって、何人かの方にはわざわざDMまで頂いてどんな勉強をしたか聞いていただきました。なるほど需要があるならということで、今までのことをまるっと振り返ってみようと思います。 これからkaggle始める方のためになれば幸いです。 機械学習を始める…
</p>
<div style='clear: both;'></div>
<p><p>論理パズルが題材のKaggle「<a href="https://www.kaggle.com/c/abstraction-and-reasoning-challenge?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">Abstraction and Reasoning Challenge</a>」コンペで2位入賞した<a href="https://www.kaggle.com/yujiariyasu" target="_blank">aryyyyyさん</a>による振り返り記事。機械学習の勉強を始めてからのKaggle遍歴を紹介しています。</p></p>
<p>
<img width="140" height="140" alt="Talks # 4: Sebastien Fischman - Pytorch-TabNet: Beating XGBoost on Tabular Data Using Deep Learning" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/106/989/thumb/maxresdefault.jpg?1591930903" />
<strong style='display: block;'><a href="https://www.youtube.com/watch?feature=youtu.be&amp;utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter&amp;v=ysBaZO8YmX8">Talks # 4: Sebastien Fischman - Pytorch-TabNet: Beating XGBoost on Tabular Data Using Deep Learning</a> &mdash; <a href="https://www.youtube.com/watch?v=ysBaZO8YmX8&amp;feature=youtu.be">www.youtube.com</a></strong>
Talks # 4: Speaker: Sebastien Fischman (https://www.linkedin.com/in/sebastienfischman/) Title : Pytorch-tabnet : Beating XGBoost on tabular data with deep le...
</p>
<div style='clear: both;'></div>
<p><p>テーブルデータ向けのニューラルネットワーク「<a href="https://arxiv.org/abs/1908.07442" target="_blank">TabNet</a>」の<a href="https://github.com/dreamquark-ai/tabnet" target="_blank">PyTorch実装</a>についての講演。pip installで導入でき、sklearnと同様の使いやすいインターフェイスになっています。</p></p>
<p>
<img width="140" height="140" alt="データ分析でコードをクリーンに保つ技術 - Higu`s diary" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/103/206/thumb/20200610210812.png?1591873486" />
<strong style='display: block;'><a href="https://zerebom.hatenablog.com/entry/2020/06/11/185321?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">データ分析でコードをクリーンに保つ技術 - Higu`s diary</a> &mdash; <a href="https://zerebom.hatenablog.com/entry/2020/06/11/185321">zerebom.hatenablog.com</a></strong>
こんにちは、ひぐです。 最近データサイエンティストのための良いコーディング習慣という記事を読みました。 www.thoughtworks.com こうした方がいいよなという自分の経験則が綺麗に言語化されていてよかったです。 ここではデータ分析でコードをクリーンに保つ技術について、記事の内容と自分の取り組みを合わせて紹介したいと思います。 自分はまだチームでの開発経験などが浅いため、間違っている部分もあるかもしれません。 あらかじめご了承ください汗 コードが汚くなる要因 コードが解くべき問題の複雑さを増長させている時、そのコードは汚いと言えます。 汚いコードは汚い部屋で探し物をする時などと同じく…
</p>
<div style='clear: both;'></div>
<p><p>「<a href="https://www.thoughtworks.com/insights/blog/coding-habits-data-scientists" target="_blank">Coding habits for data scientists</a>」という英語記事の要点を、筆者の取り組みと共に紹介している記事。Notebookからスクリプトに移行する、使い回せる部分は流用するなどのテクニックがまとめられています。</p></p>
<p>
<img width="140" height="140" alt="Python: XGBoost の cv() 関数から学習済みモデルを取り出す - CUBE SUGAR CONTAINER" style="float: right; margin-left: 20px; margin-bottom: 20px;" src="https://s3.amazonaws.com/revue/items/images/006/103/213/thumb/418YjfYRlhL._SL160_.jpg?1591873583" />
<strong style='display: block;'><a href="https://blog.amedama.jp/entry/xgboost-cv-model?utm_campaign=Weekly%20Kaggle%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter">Python: XGBoost の cv() 関数から学習済みモデルを取り出す - CUBE SUGAR CONTAINER</a> &mdash; <a href="https://blog.amedama.jp/entry/xgboost-cv-model">blog.amedama.jp</a></strong>
今回は、以下のエントリを XGBoost で焼き直したもの。 つまり、XGBoost でも cv() 関数から学習済みモデルを取り出して Fold Averaging してみようという話。 blog.amedama.jp 使った環境は次のとおり。 $ sw_vers ProductName: Mac OS X ProductVersion: 10.14.6 BuildVersion: 18G5033 $ python -V Python 3.7.7 $ pip list | grep xgboost xgboost 1.1.1 下準備 必要なパッケージをインストールしておく。 $ pip in…
</p>
<div style='clear: both;'></div>
<p><p>XGBoostで交差検証を実施する関数を使いながら、学習済みモデルを取り出す方法を紹介している記事。過去には<a href="https://blog.amedama.jp/entry/lightgbm-cv-model" target="_blank">LightGBM版</a>の記事も公開されています。個別モデルの抽出について、この記事の筆者は<a href="https://twitter.com/momijiame/status/1270943901122129921?s=20" target="_blank">LightGBMのissue上</a>での相談も開始しています。</p></p>
